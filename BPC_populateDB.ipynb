{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73397651",
   "metadata": {},
   "source": [
    "# BPCorpus: Generating corpus assets\n",
    "\n",
    "Project repository: https://github.com/k-nem/bpcorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2391,
   "id": "8db88f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64340c28",
   "metadata": {},
   "source": [
    "## Original files\n",
    "\n",
    "Original HTML files were scraped from knihi.com based on author list.\n",
    "\n",
    "The files and scraping scripts can be found in ['bpcorpus-collect' repository](https://github.com/k-nem/bpcorpus-collect).\n",
    "\n",
    "Local path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2428,
   "id": "828fa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../parsed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2878fef0",
   "metadata": {},
   "source": [
    "## Collect full file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2389,
   "id": "d83bb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiles(path):\n",
    "    \"\"\"Walk through subfolders and retrieve HTML file list\"\"\"\n",
    "    htmls = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if name.endswith('.html') and 'page' not in name:\n",
    "                htmls.append(root+'/'+name)\n",
    "                \n",
    "    htmls = sorted(htmls)\n",
    "                \n",
    "    return htmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2390,
   "id": "e0132756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../../parsed/003_Ян Баршчэўскі/003_0004.html', '../../../parsed/003_Ян Баршчэўскі/003_0005.html', '../../../parsed/003_Ян Баршчэўскі/003_0007.html', '../../../parsed/003_Ян Баршчэўскі/003_0008.html', '../../../parsed/003_Ян Баршчэўскі/003_0009.html'] \n",
      "\n",
      " 5948\n"
     ]
    }
   ],
   "source": [
    "allFiles = getFiles(path)\n",
    "print(allFiles[:5], '\\n\\n', len(allFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ba66f",
   "metadata": {},
   "source": [
    "## Original location URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2392,
   "id": "72348334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get original URL from CSV download log\n",
    "with open('../../../parsed/bpc_alllinks.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    links = [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2393,
   "id": "bdb4fd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'003_0003'"
      ]
     },
     "execution_count": 2393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[3][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "id": "75c359cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrl(path):\n",
    "    \"\"\"Get original location URL\"\"\"\n",
    "    nm = path.split('/')[-1].split('.')[0]\n",
    "    url = 'https://knihi.com/'\n",
    "    for l in links:\n",
    "        if l[3] == nm:\n",
    "            url = 'https://knihi.com/' + l[10]\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2298,
   "id": "33d8e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://knihi.com//Jan_Barsceuski/Dzvie_biarozy.html'"
      ]
     },
     "execution_count": 2298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getUrl('../../../parsed/003_Ян Баршчэўскі/003_0007.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "id": "ce9f92fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://knihi.com/'"
      ]
     },
     "execution_count": 1508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getUrl('incorrect file name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d637c",
   "metadata": {},
   "source": [
    "## Filter out irrelevant files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba794f12",
   "metadata": {},
   "source": [
    "Not all files are relevant for the corpus, since only poetic forms need to be added. To determine the genres and other metadata I parse the HTML with regular expression and extract the values from JS/HTML style comments like these (the format is determined by the knihi.com source files):\n",
    "<!-- HEADER_FIELD Authors: Ян Чачот -->\n",
    "<!-- HEADER_FIELD CreationYear: 1825-1846? -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2394,
   "id": "1f582a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaP(file): \n",
    "    \"\"\"Get metadata from the files with relevant genre value to determine the final file list\"\"\"\n",
    "    \n",
    "    # genre list\n",
    "    genres = ['Верш', 'Паэма', 'Басня', 'Балада']\n",
    "    \n",
    "    with open(file,'r') as f:\n",
    "        raw = f.read()\n",
    "    \n",
    "    # the string below shows that there is no table of contents (as in a collection of works), so only singular texts are retrieved\n",
    "    if '<!-- TOC_BEGIN -->\\n<!-- TOC_END -->' in raw:\n",
    "\n",
    "        metadict = {}\n",
    "        meta = re.findall('(?<=<!-- HEADER_FIELD ).*(?= -->)', raw)\n",
    "\n",
    "        if meta: \n",
    "            for m in meta:\n",
    "                metadict[m.split(':')[0]] = m.split(':')[1].lstrip()\n",
    "\n",
    "        if 'StyleGenre' in metadict:\n",
    "\n",
    "            if '/' in metadict['StyleGenre']:\n",
    "\n",
    "                if ',' in metadict['StyleGenre']:\n",
    "                    metadict['StyleGenre'] = metadict['StyleGenre'].split(',')\n",
    "                    metadict['StyleGenre'] = [item.split('/')[1].capitalize() for item in metadict['StyleGenre'] if len(item.split('/')) > 1]\n",
    "\n",
    "                elif ';' in metadict['StyleGenre']:\n",
    "                    metadict['StyleGenre'] = metadict['StyleGenre'].split(';')\n",
    "                    metadict['StyleGenre'] = [item.split('/')[1].capitalize() for item in metadict['StyleGenre'] if len(item.split('/')) > 1]\n",
    "\n",
    "                else:\n",
    "                    metadict['StyleGenre'] = metadict['StyleGenre'].split('/')[1].capitalize()\n",
    "\n",
    "            if not isinstance(metadict['StyleGenre'], list):     \n",
    "                if metadict['StyleGenre'] in genres:\n",
    "                    \n",
    "                    return metadict, file\n",
    "\n",
    "            else:\n",
    "                styleList = [item for item in metadict['StyleGenre'] if item in genres]\n",
    "                if len(styleList) > 0:\n",
    "                    metadict['StyleGenre'] = styleList[0]\n",
    "                    \n",
    "                    return metadict, file\n",
    "                \n",
    "def getAllP(filelist):\n",
    "    \"\"\"Apply getP() to a file list\"\"\"\n",
    "    \n",
    "    allMetaList = []\n",
    "    finalFileList = []\n",
    "    \n",
    "    for file in filelist:\n",
    "        item = metaP(file)\n",
    "        if item:\n",
    "            allMetaList.append(item[0])\n",
    "            finalFileList.append(item[1])\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return allMetaList, finalFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2395,
   "id": "caf8c621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Authors': 'Уладзіслаў Сыракомля',\n",
       "  'CreationYear': '[1911-1912]?',\n",
       "  'FirstPublicationYear': '1913; 1932',\n",
       "  'LangOrig': 'pol',\n",
       "  'Pravapis': 'A2008',\n",
       "  'PublicationYear': '1997',\n",
       "  'StyleGenre': 'Балада',\n",
       "  'Title': 'Каралі',\n",
       "  'Title2': '(Пацеркі)',\n",
       "  'Translation': 'Янка Купала'},\n",
       " '../../../parsed/013_Уладзіслаў Сыракомля/013_0004.html')"
      ]
     },
     "execution_count": 2395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaP('../../../parsed/013_Уладзіслаў Сыракомля/013_0004.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2396,
   "id": "a42c1540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authors': 'Ян Баршчэўскі',\n",
       " 'CreationYear': '13.07.1841',\n",
       " 'Edition': 'Ян Баршчэўскі. Выбраныя творы. Менск, МФ «Беларускі кнігазбор», 1998.',\n",
       " 'FirstPublicationYear': '1842',\n",
       " 'LangOrig': 'pol',\n",
       " 'Pravapis': 'A1957',\n",
       " 'PublicationYear': '1998',\n",
       " 'SectionAuthor': 'Балады',\n",
       " 'StyleGenre': 'Балада',\n",
       " 'Title': 'Дзве бярозы',\n",
       " 'Title2': 'З народных паданняў',\n",
       " 'Translation': 'Кастусь Цьвірка'}"
      ]
     },
     "execution_count": 2396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pList = getAllP(allFiles)\n",
    "pList[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2403,
   "id": "ec074a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../parsed/261_Яўгенія Янішчыц/261_0012.html',\n",
       " '../../../parsed/261_Яўгенія Янішчыц/261_0014.html',\n",
       " '../../../parsed/261_Яўгенія Янішчыц/261_0015.html',\n",
       " '../../../parsed/265_Леанід Галубовіч/265_0001.html',\n",
       " '../../../parsed/265_Леанід Галубовіч/265_0002.html']"
      ]
     },
     "execution_count": 2403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pList[1][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2404,
   "id": "e3645db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3068"
      ]
     },
     "execution_count": 2404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pList[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b10706",
   "metadata": {},
   "source": [
    "This list will be used for corpus generation. Folder structure is arbitrary since metadata is located in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "88becc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in pList[0]:\n",
    "#     if 'LangOrig' in i:\n",
    "#         if i['LangOrig'] == 'yid':\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "id": "d8bc6b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deu', 'lat', 'pol', 'rus', 'ukr', 'yid'}"
      ]
     },
     "execution_count": 1357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all original languages for translated works\n",
    "set([i['LangOrig'] for i in pList[0] if 'LangOrig' in i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6792998",
   "metadata": {},
   "source": [
    "## Author index ID\n",
    "This dictionary will be used to provide author IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "21ad5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allAuthors(metalist):\n",
    "    \"\"\"Get author work count\"\"\"\n",
    "    \n",
    "    authors = {}\n",
    "\n",
    "    for item in metalist:\n",
    "        if 'Authors' in item.keys():\n",
    "            if item['Authors'] not in authors.keys():\n",
    "                authors[item['Authors']] = 1\n",
    "                \n",
    "            else:\n",
    "                authors[item['Authors']] += 1\n",
    "                \n",
    "        if 'Translation' in item.keys():\n",
    "            if item['Translation'] not in authors.keys():\n",
    "                authors[item['Translation']] = 1\n",
    "                \n",
    "            else:\n",
    "                authors[item['Translation']] += 1\n",
    "\n",
    "    return authors\n",
    "\n",
    "def authIds(authlist):\n",
    "    \"\"\"Generate author IDs and name dictionaries for tree population\"\"\"\n",
    "    \n",
    "    order = sorted(authlist, key=lambda x: str(x.split()[-1]))\n",
    "    authIds = {}\n",
    "    \n",
    "    for i, name in enumerate(order):\n",
    "\n",
    "        names = name.split()\n",
    "\n",
    "        if len(names) == 2:\n",
    "            forename = names[0]\n",
    "            surname = names[1]\n",
    "            names = {'Forename': forename, 'Surname': surname}\n",
    "            authIds[name] = {'name': names, 'id': i + 1}\n",
    "            \n",
    "        else:\n",
    "            authIds[name] = {'name': name, 'id': i + 1}\n",
    "        \n",
    "    return authIds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2405,
   "id": "72ff3a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authCounts = allAuthors(pList[0])\n",
    "authCounts['Цётка']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2408,
   "id": "ce133311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ян Баршчэўскі': 8,\n",
       " 'Кастусь Цьвірка': 1,\n",
       " 'Уладзімір Мархель': 8,\n",
       " 'Рыгор Барадулін': 23,\n",
       " 'Ян Чачот': 3,\n",
       " 'Уладзіслаў Сыракомля': 11,\n",
       " 'Янка Купала': 860,\n",
       " 'Кастусь Каліноўскі': 1,\n",
       " 'Францішак Багушэвіч': 36,\n",
       " 'Міхась Машара': 1,\n",
       " 'Сяржук Сокалаў-Воюш': 2,\n",
       " 'Максім Танк': 24,\n",
       " 'Куба Паўтаржыцкі': 1,\n",
       " 'Пятро Бітэль': 1,\n",
       " 'Алег Лойка': 4,\n",
       " 'Янка Лучына': 2,\n",
       " 'Генадзь Тумаш': 1,\n",
       " 'Цётка': 4,\n",
       " 'Кароль Балінскі': 1,\n",
       " 'Герман Гесэ': 1,\n",
       " 'М. Ісакоўскі': 1,\n",
       " 'Аляксей Кальцоў': 1,\n",
       " 'Марыя Канапніцкая': 11,\n",
       " 'Ян Каспровіч': 1,\n",
       " 'М. Красільнікаў': 1,\n",
       " 'Юзаф Крашэўскі': 2,\n",
       " 'Іван Крылоў': 1,\n",
       " 'Раіса Кудашава': 1,\n",
       " 'Адам Міцкевіч': 9,\n",
       " 'Невядомы': 6,\n",
       " 'Мікалай Някрасаў': 5,\n",
       " \"Валяр'ян Паляшчук\": 1,\n",
       " 'Іда Пілецкая': 1,\n",
       " 'Карнель Уейскі': 1,\n",
       " 'Дзмітрый Цэнзар': 1,\n",
       " 'Фёдар Цютчаў': 1,\n",
       " 'Грыцька Чупрынка': 2,\n",
       " 'Тарас Шаўчэнка': 35,\n",
       " 'Піліп Шкулёў': 1,\n",
       " 'Л. Явалкоўская-Кашуцкая': 1,\n",
       " 'Яскулка': 1,\n",
       " 'Якуб Колас': 808,\n",
       " 'Сяргей Гарадзецкі': 2,\n",
       " 'Максім Рыльскі': 1,\n",
       " 'Паўло Тычына': 1,\n",
       " 'Георг Хэрвег': 1,\n",
       " 'Максім Багдановіч': 21,\n",
       " 'Алесь Гарун': 159,\n",
       " 'Уладзіслаў Галубок': 6,\n",
       " 'Цішка Гартны': 77,\n",
       " 'Янка Журба': 1,\n",
       " 'Канстанцыя Буйло': 23,\n",
       " 'Зоська Верас': 1,\n",
       " 'Міхась Чарот': 14,\n",
       " 'Кандрат Крапіва': 150,\n",
       " 'Уладзімір Жылка': 1,\n",
       " 'Уладзімір Дубоўка': 9,\n",
       " 'Язэп Пушча': 6,\n",
       " 'Мікола Гусоўскі': 1,\n",
       " 'Натальля Арсеньнева; Віктар Дарашкевіч': 1,\n",
       " 'Адам Русак': 1,\n",
       " 'Пятрусь Броўка': 18,\n",
       " 'Пятро Глебка': 17,\n",
       " 'Алесь Звонак': 4,\n",
       " 'Максім Лужанін': 22,\n",
       " 'Ларыса Геніюш': 2,\n",
       " 'Васіль Вітка': 7,\n",
       " 'Аляксей Русецкі': 1,\n",
       " 'Сяргей Грахоўскі': 6,\n",
       " 'Аркадзь Куляшоў': 57,\n",
       " 'Пімен Панчанка': 292,\n",
       " 'Алесь Бачыла': 1,\n",
       " 'Аляксей Пысін': 18,\n",
       " 'Анатоль Вялюгін': 1,\n",
       " 'Еўдакія Лось': 5,\n",
       " 'Уладзімір Караткевіч': 320,\n",
       " 'Ніл Гілевіч': 12,\n",
       " 'Анатоль Вярцінскі': 4,\n",
       " 'Юрась Свірка': 2,\n",
       " 'Марк Шагал': 6,\n",
       " 'Васіль Зуёнак': 5,\n",
       " 'Янка Сіпакоў': 2,\n",
       " 'Данута Бічэль-Загнетава': 8,\n",
       " 'Анатоль Грачанікаў': 7,\n",
       " 'Ніна Мацяш': 5,\n",
       " 'Раіса Баравікова': 3,\n",
       " 'Алесь Разанаў': 3,\n",
       " 'Яўгенія Янішчыц': 8,\n",
       " 'Леанід Галубовіч': 2}"
      ]
     },
     "execution_count": 2408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2411,
   "id": "5b304a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': {'Forename': 'Кастусь', 'Surname': 'Цьвірка'}, 'id': 77},\n",
       " {'name': 'Цётка', 'id': 80}]"
      ]
     },
     "execution_count": 2411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authDict = authIds(authCounts.keys())\n",
    "[authDict['Кастусь Цьвірка'], authDict['Цётка']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f853c",
   "metadata": {},
   "source": [
    "## Check the most used tags within texts (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229044d",
   "metadata": {},
   "source": [
    "The following code doesn't serve any function in the generation of the corpus apart from collecting information about the most used tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "id": "f76ff52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allTags(path):\n",
    "    \"\"\"Full tag list for a file\"\"\"\n",
    "    \n",
    "    with open(path,'r') as f:\n",
    "        raw = f.read()\n",
    "        \n",
    "    pat = re.compile('(?<=(<!-- BOOK_BEGIN -->))(\\s.*\\s?)*(?=(<!-- BOOK_END -->))')\n",
    "    tags = re.search(pat, raw)\n",
    "    \n",
    "    if tags: \n",
    "        soup = BeautifulSoup(tags.group(0),'html.parser')   \n",
    "        taglist = [[tag.name, tag.text, tag.attrs] for tag in soup.find_all()]\n",
    "    \n",
    "    return taglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "id": "a4f56041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['p', 'З польскай — У. Сыракомлі', {}],\n",
       " ['i', 'З польскай — У. Сыракомлі', {}],\n",
       " ['p', '\\xa0', {}],\n",
       " ['p', 'Як ішоў я ў бой кіпячы,', {}],\n",
       " ['p', 'Як прашчаўся з хаткай,', {}],\n",
       " ['p', 'Тут Гануля мая з плачам:', {}],\n",
       " ['p', '«Пойдзеш гінуць, братка!', {}],\n",
       " ['p', 'Але буду я маліцца', {}],\n",
       " ['p', 'Па табе з трывогі,', {}],\n",
       " ['p', 'Ты ж прынось за то гасцінца —', {}]]"
      ]
     },
     "execution_count": 1673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allTags('../../../parsed/013_Уладзіслаў Сыракомля/013_0004.html')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2412,
   "id": "23986f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagCounts(files):  \n",
    "    \"\"\"Count non-empty tags\"\"\"\n",
    "    tagCount = {}\n",
    "    divs = []\n",
    "    sups = []\n",
    "    links = []\n",
    "    cen = []\n",
    "    bs = []\n",
    "    ps = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file,'r') as f:\n",
    "            raw = f.read()\n",
    "\n",
    "        pat = re.compile('(?<=(<!-- BOOK_BEGIN -->))(\\s.*\\s?)*(?=(<!-- BOOK_END -->))')\n",
    "        tags = re.search(pat, raw)\n",
    "\n",
    "        if tags:\n",
    "            soup = BeautifulSoup(tags.group(0),'html.parser')   \n",
    "            taglist = [[tag.name, tag.text, tag.attrs] for tag in soup.find_all()]\n",
    "\n",
    "            for tag in taglist:\n",
    "                if tag[1].strip():\n",
    "                    if tag[0] == 'div':\n",
    "                        if tag[2]['class']:\n",
    "                            if tag[2]['class'] == ['POETRY']:\n",
    "                                continue  \n",
    "\n",
    "                            else:\n",
    "                                divs.append([file, tag])\n",
    "\n",
    "                                if tag[0] not in tagCount.keys():\n",
    "                                    tagCount[tag[0]] = 1\n",
    "\n",
    "                                else:\n",
    "                                    tagCount[tag[0]] += 1\n",
    "\n",
    "                        else:\n",
    "                                divs.append([file, tag])\n",
    "\n",
    "                                if tag[0] not in tagCount.keys():\n",
    "                                    tagCount[tag[0]] = 1\n",
    "\n",
    "                                else:\n",
    "                                    tagCount[tag[0]] += 1\n",
    "\n",
    "                    elif tag[0] == 'sup':\n",
    "                        sups.append([file, tag])\n",
    "\n",
    "                        if tag[0] not in tagCount.keys():\n",
    "                            tagCount[tag[0]] = 1\n",
    "\n",
    "                        else:\n",
    "                            tagCount[tag[0]] += 1\n",
    "\n",
    "                    elif tag[0] == 'a':\n",
    "                        links.append([file, tag])\n",
    "\n",
    "                        if tag[0] not in tagCount.keys():\n",
    "                            tagCount[tag[0]] = 1\n",
    "\n",
    "                        else:\n",
    "                            tagCount[tag[0]] += 1\n",
    "\n",
    "                    elif tag[0] == 'center':\n",
    "                        cen.append([file, tag])\n",
    "\n",
    "                        if tag[0] not in tagCount.keys():\n",
    "                            tagCount[tag[0]] = 1\n",
    "\n",
    "                        else:\n",
    "                            tagCount[tag[0]] += 1\n",
    "\n",
    "                    elif tag[0] == 'b':\n",
    "                        bs.append([file, tag])\n",
    "\n",
    "                        if tag[0] not in tagCount.keys():\n",
    "                            tagCount[tag[0]] = 1\n",
    "\n",
    "                        else:\n",
    "                            tagCount[tag[0]] += 1\n",
    "\n",
    "                    elif tag[0] == 'p':\n",
    "                        if tag[1] != '\\xa0':\n",
    "                            ps.append([file, tag])\n",
    "\n",
    "                        if tag[0] not in tagCount.keys():\n",
    "                            tagCount[tag[0]] = 1\n",
    "\n",
    "                        else:\n",
    "                            tagCount[tag[0]] += 1\n",
    "\n",
    "    return tagCount, divs, sups, links, cen, bs, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2413,
   "id": "ff790a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagInfo = tagCounts(pList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2414,
   "id": "e5800083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': 127450, 'sup': 101, 'b': 159, 'a': 94, 'div': 163, 'center': 42}"
      ]
     },
     "execution_count": 2414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagInfo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2422,
   "id": "056f80d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../../../parsed/028_Янка Купала/028_0493.html',\n",
       "  ['div', '\\n1 Суомі — Фінляндыя.\\n\\n', {'class': ['endnote-block']}]],\n",
       " ['../../../parsed/028_Янка Купала/028_0493.html',\n",
       "  ['div', '1 Суомі — Фінляндыя.\\n', {'class': ['footnote']}]],\n",
       " ['../../../parsed/028_Янка Купала/028_0561.html',\n",
       "  ['div',\n",
       "   '\\nЕўрапейскія дзяржавы пастанавілі запрасіць на міжнародную нараду ў Геную т. Леніна.\\n\\xa0\\nЗ газет 1921 г.\\n',\n",
       "   {'class': ['EPIGRAPH']}]]]"
      ]
     },
     "execution_count": 2422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagInfo[1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2423,
   "id": "5e254e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../../../parsed/003_Ян Баршчэўскі/003_0007.html', ['sup', '1', {}]],\n",
       " ['../../../parsed/028_Янка Купала/028_0493.html', ['sup', '1', {}]],\n",
       " ['../../../parsed/028_Янка Купала/028_0493.html', ['sup', '1', {}]]]"
      ]
     },
     "execution_count": 2423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagInfo[2][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2424,
   "id": "a89a62d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../../../parsed/028_Янка Купала/028_0493.html',\n",
       "  ['a', '1', {'href': '#footnote-1'}]],\n",
       " ['../../../parsed/028_Янка Купала/028_0493.html',\n",
       "  ['a', '1', {'id': 'footnote-1'}]],\n",
       " ['../../../parsed/032_Алесь Гарун/032_0016.html',\n",
       "  ['a', '42', {'href': '#footnote-1'}]]]"
      ]
     },
     "execution_count": 2424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagInfo[3][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2425,
   "id": "356babd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../../../parsed/029_Якуб Колас/029_0401.html', ['center', '*', {}]],\n",
       " ['../../../parsed/029_Якуб Колас/029_0401.html', ['center', '*', {}]],\n",
       " ['../../../parsed/029_Якуб Колас/029_0401.html', ['center', '*', {}]]]"
      ]
     },
     "execution_count": 2425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagInfo[4][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2430,
   "id": "87566019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../../../parsed/003_Ян Баршчэўскі/003_0007.html', ['b', 'Каментары', {}]],\n",
       " ['../../../parsed/003_Ян Баршчэўскі/003_0008.html', ['b', 'Каментары', {}]],\n",
       " ['../../../parsed/003_Ян Баршчэўскі/003_0009.html', ['b', 'Каментары', {}]]]"
      ]
     },
     "execution_count": 2430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagInfo[5][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2420,
   "id": "76fd5de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../../../parsed/003_Ян Баршчэўскі/003_0007.html',\n",
       "  ['p', 'Ведае вёска: так шчыра Марылю', {}]],\n",
       " ['../../../parsed/003_Ян Баршчэўскі/003_0007.html',\n",
       "  ['p', 'Ясь, маладую, кахае!', {}]],\n",
       " ['../../../parsed/003_Ян Баршчэўскі/003_0007.html',\n",
       "  ['p', 'З Полацка возіць ёй стужкі штохвілю,', {}]]]"
      ]
     },
     "execution_count": 2420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagInfo[6][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2421,
   "id": "f09f4872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../../../parsed/019_Янка Лучына/019_0001.html', '* * *'],\n",
       " ['../../../parsed/019_Янка Лучына/019_0001.html', '* * *'],\n",
       " ['../../../parsed/019_Янка Лучына/019_0001.html', '* * *'],\n",
       " ['../../../parsed/019_Янка Лучына/019_0001.html', '* * *'],\n",
       " ['../../../parsed/019_Янка Лучына/019_0001.html', '* * *']]"
      ]
     },
     "execution_count": 2421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[p[0], p[1][1]] for p in tagInfo[6] if p[1][1] == '* * *'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594c6c1",
   "metadata": {},
   "source": [
    "## Build XML tree I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb81d8",
   "metadata": {},
   "source": [
    "Generation a XML tree with TEI header and verse structure on stanza level `<lg>` (tokenization and lemmatization will be performed at a later stage and a wider context is necessary for higher accuracy of tagging). Meta elements like epigraphs, footnotes and headings are placed into `<seg>` tags so that they are not included in lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "e0937544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRaw(path):\n",
    "    \"\"\"Open file\"\"\"\n",
    "    with open(path,'r') as f:\n",
    "        raw = f.read()   \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2307,
   "id": "fc082f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta(raw): \n",
    "    \"\"\"Get metadata (without filtering)\"\"\"\n",
    "\n",
    "    metadict = {}\n",
    "    meta = re.findall('(?<=<!-- HEADER_FIELD ).*(?= -->)', raw)\n",
    "\n",
    "    if meta: \n",
    "        for m in meta:\n",
    "            metadict[m.split(':')[0]] = m.split(':')[1].lstrip()\n",
    "\n",
    "            \n",
    "    if 'Authors' in metadict:\n",
    "        if isinstance(authDict[metadict['Authors']]['name'], dict):\n",
    "            metadict['Forename'] = authDict[metadict['Authors']]['name']['Forename']\n",
    "            metadict['Surname'] = authDict[metadict['Authors']]['name']['Surname']\n",
    "            \n",
    "        metadict['aid'] = authDict[metadict['Authors']]['id']\n",
    "        \n",
    "        \n",
    "    if 'Translation' in metadict:\n",
    "        if isinstance(authDict[metadict['Translation']]['name'], dict):\n",
    "            metadict['trForename'] = authDict[metadict['Translation']]['name']['Forename']\n",
    "            metadict['trSurname'] = authDict[metadict['Translation']]['name']['Surname']\n",
    "            \n",
    "        metadict['tid'] = authDict[metadict['Translation']]['id']\n",
    "\n",
    "    if 'StyleGenre' in metadict:\n",
    "\n",
    "        if '/' in metadict['StyleGenre']:\n",
    "\n",
    "            if ',' in metadict['StyleGenre']:\n",
    "                metadict['StyleGenre'] = metadict['StyleGenre'].split(',')\n",
    "                metadict['StyleGenre'] = [item.split('/')[1].capitalize() for item in metadict['StyleGenre'] if len(item.split('/')) > 1]\n",
    "\n",
    "            elif ';' in metadict['StyleGenre']:\n",
    "                metadict['StyleGenre'] = metadict['StyleGenre'].split(';')\n",
    "                metadict['StyleGenre'] = [item.split('/')[1].capitalize() for item in metadict['StyleGenre'] if len(item.split('/')) > 1]\n",
    "\n",
    "            else:\n",
    "                metadict['StyleGenre'] = metadict['StyleGenre'].split('/')[1].capitalize()\n",
    "\n",
    "        else:\n",
    "            styleList = [item for item in metadict['StyleGenre'] if item in genres]\n",
    "            metadict['StyleGenre'] = styleList[0]\n",
    "            \n",
    "        if isinstance(metadict['StyleGenre'], list):\n",
    "            metadict['StyleGenre'] = metadict['StyleGenre'][0]\n",
    "            \n",
    "    attrs = ['Authors', 'CreationYear', 'Edition', 'FirstPublicationYear', 'LangOrig', 'PublicationYear', 'StyleGenre', 'Title', 'Translation', 'Forename', 'Surname', 'trForename', 'trSurname', 'tid']\n",
    "    for a in attrs:\n",
    "        if a not in metadict.keys():\n",
    "            metadict[a] = None\n",
    "    \n",
    "    return metadict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2308,
   "id": "cb469014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authors': 'Уладзіслаў Сыракомля',\n",
       " 'CreationYear': '[1911-1912]?',\n",
       " 'FirstPublicationYear': '1913; 1932',\n",
       " 'LangOrig': 'pol',\n",
       " 'Pravapis': 'A2008',\n",
       " 'PublicationYear': '1997',\n",
       " 'StyleGenre': 'Балада',\n",
       " 'Title': 'Каралі',\n",
       " 'Title2': '(Пацеркі)',\n",
       " 'Translation': 'Янка Купала',\n",
       " 'Forename': 'Уладзіслаў',\n",
       " 'Surname': 'Сыракомля',\n",
       " 'aid': 70,\n",
       " 'trForename': 'Янка',\n",
       " 'trSurname': 'Купала',\n",
       " 'tid': 47,\n",
       " 'Edition': None}"
      ]
     },
     "execution_count": 2308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta(getRaw('../../../parsed/013_Уладзіслаў Сыракомля/013_0004.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2309,
   "id": "b4dd7b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authors': 'Цётка',\n",
       " 'CreationYear': '1905',\n",
       " 'Edition': 'Беларуская літаратура ',\n",
       " 'FirstPublicationYear': '1905?',\n",
       " 'Pravapis': 'A1957',\n",
       " 'PublicationYear': '2004',\n",
       " 'SectionAuthor': 'Вершы',\n",
       " 'Source': 'скан',\n",
       " 'StyleGenre': 'Верш',\n",
       " 'Title': 'Вера беларуса',\n",
       " 'Uploaded': '2011-08-04T12',\n",
       " 'Year': '1905',\n",
       " 'aid': 80,\n",
       " 'LangOrig': None,\n",
       " 'Translation': None,\n",
       " 'Forename': None,\n",
       " 'Surname': None,\n",
       " 'trForename': None,\n",
       " 'trSurname': None,\n",
       " 'tid': None}"
      ]
     },
     "execution_count": 2309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta(getRaw('../../../parsed/026_Цётка/026_0002.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2388,
   "id": "72026795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTree(raw, treemeta, fileName):\n",
    "    \"\"\"Step 1. Generate TEI header and line group structure after collecting metadata\"\"\"\n",
    "    \n",
    "    #raw = getRaw(file)\n",
    "    #treemeta = meta(raw)\n",
    "    newtree = BeautifulSoup('', 'xml')\n",
    "    newtree.append(newtree.new_tag('TEI'))\n",
    "    \n",
    "    # teiHeader\n",
    "    \n",
    "    head = newtree.new_tag('teiHeader')\n",
    "    head.append(newtree.new_tag('fileDesc'))\n",
    "    \n",
    "    # titleStmt\n",
    "    \n",
    "    titlest = newtree.new_tag('titleStmt')\n",
    "    \n",
    "    if 'Title' in treemeta:\n",
    "        if treemeta['Title']:\n",
    "            titlest.append(newtree.new_tag('title'))\n",
    "            titlest.title.string = treemeta['Title']\n",
    "        \n",
    "    if 'Title2' in treemeta: \n",
    "        if treemeta['Title2']:\n",
    "            titlest.append(newtree.new_tag('subtitle'))\n",
    "            titlest.subtitle.string = treemeta['Title2']\n",
    "    \n",
    "    titlest.append(newtree.new_tag('author'))\n",
    "    titlest.author.append(newtree.new_tag('persName'))\n",
    "    \n",
    "    if 'Authors' in treemeta:\n",
    "        if treemeta['Authors']:\n",
    "            titlest.author.persName['ident'] = treemeta['aid']\n",
    "            if treemeta['Forename']:\n",
    "                titlest.author.persName.append(newtree.new_tag('forename'))\n",
    "                titlest.author.persName.forename.string = treemeta['Forename']\n",
    "                titlest.author.persName.append(newtree.new_tag('surname'))\n",
    "                titlest.author.persName.surname.string = treemeta['Surname']\n",
    "\n",
    "            else:\n",
    "                nm = newtree.new_tag('name')\n",
    "                nm.string = treemeta['Authors']\n",
    "                titlest.author.persName.append(nm)\n",
    "        \n",
    "    head.fileDesc.append(titlest)\n",
    "        \n",
    "    # sourceDesc\n",
    "    \n",
    "    src = newtree.new_tag('sourceDesc')\n",
    "    \n",
    "    if 'Edition' in treemeta:\n",
    "        if treemeta['Edition']:\n",
    "            origs = newtree.new_tag('bibl')\n",
    "            origs['type'] = 'originalSource'\n",
    "            origs.string = treemeta['Edition']\n",
    "            src.append(origs)\n",
    "        \n",
    "    digs = newtree.new_tag('bibl')\n",
    "    digs['type'] = 'digitalSource'\n",
    "    digs.append(newtree.new_tag('ptr'))\n",
    "    digs.ptr['target'] = getUrl(fileName)\n",
    "    src.append(digs)\n",
    "    \n",
    "    head.fileDesc.append(src)\n",
    "    \n",
    "    # profileDesc\n",
    "    \n",
    "    prof = newtree.new_tag('profileDesc')\n",
    "    tc = newtree.new_tag('textClass')\n",
    "    prof.append(tc)\n",
    "    kw = newtree.new_tag('keywords')\n",
    "    tc.append(kw)\n",
    "    \n",
    "    lu = newtree.new_tag('langUsage')\n",
    "    lang = newtree.new_tag('language')\n",
    "    lang['ident'] = 'be'\n",
    "    lang.string = 'Беларуская'\n",
    "    lu.append(lang)\n",
    "    prof.append(lu)\n",
    "    \n",
    "    form = newtree.new_tag('term')\n",
    "    form['type'] = 'form'\n",
    "    form.string = 'Паэзія'\n",
    "    kw.append(form)\n",
    "    \n",
    "    if 'StyleGenre' in treemeta:  \n",
    "        if treemeta['StyleGenre']: \n",
    "            genre = newtree.new_tag('term')\n",
    "            genre['type'] = 'genre'\n",
    "            genre.string = treemeta['StyleGenre']\n",
    "            kw.append(genre)\n",
    "        \n",
    "    head.fileDesc.append(prof)\n",
    "    \n",
    "    # textDesc\n",
    "    \n",
    "    txtd = newtree.new_tag('textDesc')\n",
    "    \n",
    "    if 'creationYear' in treemeta:\n",
    "        if treemeta['creationYear']: \n",
    "            txtd.append(newtree.new_tag('creationYear'))\n",
    "            txtd.creationYear['when'] = treemeta['CreationYear']\n",
    "            txtd.creationYear.string = treemeta['CreationYear']\n",
    "        \n",
    "    if 'publicationYear' in treemeta:\n",
    "        if treemeta['publicationYear']: \n",
    "            txtd.append(newtree.new_tag('publicationYear'))\n",
    "            txtd.publicationYear['when'] = treemeta['PublicationYear']\n",
    "            txtd.publicationYear.string = treemeta['PublicationYear']\n",
    "\n",
    "    if 'FirstPublicationYear' in treemeta:\n",
    "        if treemeta['FirstPublicationYear']: \n",
    "            txtd.append(newtree.new_tag('firstPublicationYear'))\n",
    "            txtd.firstPublicationYear['when'] = treemeta['FirstPublicationYear']\n",
    "            txtd.firstPublicationYear.string = treemeta['FirstPublicationYear']\n",
    "    \n",
    "    if 'Translation' in treemeta:\n",
    "        if treemeta['Translation']:\n",
    "            tra = newtree.new_tag('translator')\n",
    "            tra['ident'] = treemeta['tid']\n",
    "            if treemeta['trForename']:\n",
    "                tra.append(newtree.new_tag('forename'))\n",
    "                tra.forename.string = treemeta['trForename']\n",
    "                tra.append(newtree.new_tag('surname'))\n",
    "                tra.surname.string = treemeta['trSurname']\n",
    "\n",
    "            else:\n",
    "                nm = newtree.new_tag('name')\n",
    "                nm.string = treemeta['Translation']\n",
    "                tra.append(nm)\n",
    "                \n",
    "            txtd.append(tra)\n",
    "        \n",
    "    if 'LangOrig' in treemeta:\n",
    "        if treemeta['LangOrig']:\n",
    "            lNames = {'deu':['de', 'Нямецкая' ], 'lat': ['la', 'Лацінская'], 'pol': ['pl', 'Польская'], 'rus': ['ru', 'Руская'], 'ukr': ['uk', 'Украінская'], 'yid': ['yi', 'Ідыш']}\n",
    "\n",
    "            lo = newtree.new_tag('originalLanguage')\n",
    "            lo['ident'] = lNames[treemeta['LangOrig']][0]\n",
    "            lo.string = lNames[treemeta['LangOrig']][1]\n",
    "            txtd.append(lo)\n",
    "    \n",
    "    head.fileDesc.append(txtd)\n",
    "\n",
    "    newtree.TEI.append(head)\n",
    "    \n",
    "    body = newtree.new_tag('body')\n",
    "    newtree.TEI.append(body)\n",
    "    \n",
    "    # parse body\n",
    "    \n",
    "    pat = re.compile('(?<=(<!-- BOOK_BEGIN -->))(\\s.*\\s?)*(?=(<!-- BOOK_END -->))')\n",
    "    textbody = re.search(pat, raw)\n",
    "\n",
    "    soup = BeautifulSoup(textbody.group(0),'html.parser')\n",
    "    tags = [[tag.name, tag.text, tag.attrs] for tag in soup.find_all()]\n",
    "    \n",
    "    lg = newtree.new_tag('lg')\n",
    "    lg.string = ''\n",
    "    \n",
    "    if 'EPIGRAPH' in [tag[2]['class'][0] for tag in tags if tag[0]== 'div' and tag[2]['class']]:\n",
    "        for i,item in enumerate(tags):\n",
    "            if item[2]:\n",
    "                if 'class' in item[2]:\n",
    "                    if item[2]['class'][0] == 'CLEAR':\n",
    "                        for tag in tags[:i]:\n",
    "                            if tag[2]:\n",
    "                                if 'class' in tag[2]:\n",
    "                                    if tag[2]['class'][0] == 'EPIGRAPH':\n",
    "                                        seg = newtree.new_tag('seg')\n",
    "                                        seg['type'] = 'epigraph'\n",
    "\n",
    "                                        for line in tag[1].strip().split('\\n'):\n",
    "                                            l = newtree.new_tag('l')\n",
    "                                            l['type'] = 'ep'\n",
    "                                            l.string = line\n",
    "                                            seg.append(l)\n",
    "\n",
    "                                        newtree.body.append(seg)\n",
    "\n",
    "                        tags = tags[i+1:]\n",
    "                    \n",
    "    cseg = None\n",
    "    \n",
    "    if ['b','Каментары', {}] in tags:\n",
    "        for i,item in enumerate (tags):\n",
    "            if ['b','Каментары', {}] == item:\n",
    "                coms = [tag[1] for tag in tags[i+1:] if tag[0] == 'p']\n",
    "                cseg = newtree.new_tag('seg')\n",
    "                cseg['type'] = 'footnotes'\n",
    "                \n",
    "                for c in [c for c in coms if c != '\\xa0']:\n",
    "                    l = newtree.new_tag('l')\n",
    "                    dig = re.search('^\\d{1,2}[\\.|\\)]?(?=[^\\d])', c)\n",
    "                        \n",
    "                    if dig:\n",
    "                        s = newtree.new_tag('num')\n",
    "                        s.string = dig.group().strip('.)')\n",
    "                        l.append(s)\n",
    "\n",
    "                        com = newtree.new_tag('footnote')\n",
    "                        com.string = c.replace(dig.group(),'').strip()\n",
    "                        l.append(com)\n",
    "\n",
    "                    else:\n",
    "                        com = newtree.new_tag('footnote')\n",
    "                        com.string = c\n",
    "                        l.append(com)\n",
    "\n",
    "                    cseg.append(l) \n",
    "\n",
    "                tags = tags[:i-1]\n",
    "  \n",
    "\n",
    "    for i,tag in enumerate(tags): \n",
    "        if i == len(tags) - 1 and lg.string != '':        \n",
    "            newtree.body.append(lg)\n",
    "            \n",
    "        else:\n",
    "            if tag[0] == 'p':   \n",
    "                if tag[1] == '\\xa0':\n",
    "                    if lg.string:\n",
    "                        newtree.body.append(lg)\n",
    "                        lg = newtree.new_tag('lg')\n",
    "                        lg.string = ''\n",
    "                    \n",
    "                elif tag[1] == '*' or tag[1] == '* * *':\n",
    "                    if lg.string:\n",
    "                        newtree.body.append(lg)\n",
    "                        lg = newtree.new_tag('lg')\n",
    "                        lg.string = ''\n",
    "                        \n",
    "                    seg = newtree.new_tag('seg')\n",
    "                    seg.string = tag[1]\n",
    "                    seg['type'] = 'divider'\n",
    "                    newtree.body.append(seg)\n",
    "                    \n",
    "                elif tags[i + 1][0] == 'i' and tags[i + 1][1] == tag[1]:\n",
    "                    if lg.string:\n",
    "                        newtree.body.append(lg)\n",
    "                        lg = newtree.new_tag('lg')\n",
    "                        lg.string = ''\n",
    "                            \n",
    "                    seg = newtree.new_tag('seg')\n",
    "                    seg.string = tag[1]\n",
    "                    seg['type'] = 'italic'\n",
    "                    newtree.body.append(seg)\n",
    "                    \n",
    "                elif tags[i + 1][0] == 'b' and tags[i + 1][1] == tag[1]:\n",
    "                    if lg.string:\n",
    "                        newtree.body.append(lg)\n",
    "                        lg = newtree.new_tag('lg')\n",
    "                        lg.string = ''\n",
    "                            \n",
    "                    seg = newtree.new_tag('seg')\n",
    "                    seg.string = tag[1]\n",
    "                    seg['type'] = 'header'\n",
    "                    newtree.body.append(seg)\n",
    "                    \n",
    "                elif tag[1] == ' ':\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    year = re.findall('[1|2]\\d{3}', tag[1])\n",
    "                    \n",
    "                    if year:\n",
    "                        if lg.string:\n",
    "                            newtree.body.append(lg)\n",
    "                            lg = newtree.new_tag('lg')\n",
    "                            lg.string = ''\n",
    "                        \n",
    "                        seg = newtree.new_tag('seg')\n",
    "                        seg.string = tag[1]\n",
    "                        seg['type'] = 'timestamp'\n",
    "                        newtree.body.append(seg)\n",
    "                        \n",
    "                    else: \n",
    "                        lg.string += tag[1] + '\\n'\n",
    "     \n",
    "\n",
    "            elif tag[0] == 'div':\n",
    "                \n",
    "                if tag[2]['class'][0] == 'endnote-block' and tag[1].strip():\n",
    "                    if lg.string:\n",
    "                        newtree.body.append(lg)\n",
    "                        \n",
    "                    coms = [tag[1] for tag in tags[i+1:] if tag[0] == 'p']\n",
    "\n",
    "                    cseg = newtree.new_tag('seg')\n",
    "                    cseg['type'] = 'footnotes'\n",
    "\n",
    "                    for c in [c for c in coms if c != '\\xa0']:\n",
    "                        l = newtree.new_tag('l')\n",
    "                        dig = re.search('^\\d{1,2}[\\.|\\)]?(?=[^\\d])', c)\n",
    "\n",
    "                        if dig:\n",
    "                            s = newtree.new_tag('num')\n",
    "                            s.string = dig.group().strip('.)')\n",
    "                            l.append(s)\n",
    "\n",
    "                            com = newtree.new_tag('footnote')\n",
    "                            com.string = c.replace(dig.group(),'').strip()\n",
    "                            l.append(com)\n",
    "\n",
    "                        else:\n",
    "                            com = newtree.new_tag('footnote')\n",
    "                            com.string = c\n",
    "                            l.append(com)\n",
    "\n",
    "\n",
    "                        cseg.append(l) \n",
    "\n",
    "                    newtree.body.append(cseg)\n",
    "                    break\n",
    "                    \n",
    "            elif tag[0] == 'center':\n",
    "                if lg.string:\n",
    "                    newtree.body.append(lg)\n",
    "                    lg = newtree.new_tag('lg')\n",
    "                    lg.string = ''\n",
    "\n",
    "                seg = newtree.new_tag('seg')\n",
    "                seg.string = tag[1]\n",
    "                \n",
    "                if tag[1] == '*' or tag[1] == '* * *':\n",
    "                    seg['type'] = 'divider'\n",
    "                    newtree.body.append(seg)\n",
    "                    \n",
    "#             elif tag[0] == 'b':\n",
    "                \n",
    "#                 if lg.string:\n",
    "#                     newtree.body.append(lg)\n",
    "#                     lg = newtree.new_tag('lg')\n",
    "#                     lg.string = ''\n",
    "\n",
    "#                 b = newtree.new_tag('seg')\n",
    "#                 b.string = tag[1]\n",
    "#                 b['type'] = 'heading'\n",
    "#                 newtree.body.append(b)\n",
    "                    \n",
    "    if cseg != None:\n",
    "        newtree.body.append(cseg)\n",
    "    \n",
    "    return newtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2376,
   "id": "d706ba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<TEI><teiHeader><fileDesc><titleStmt><title>«Сталася здарэнне дый каля крыніцы...»</title><author><persName ident=\"21\"><forename>Алесь</forename><surname>Гарун</surname></persName></author></titleStmt><sourceDesc><bibl type=\"originalSource\">Гарун А. Сэрцам пачуты звон</bibl><bibl type=\"digitalSource\"><ptr target=\"https://knihi.com//Ales_Harun/Stalasia_zdarennie_dyj_kala_krynicy_spz.html\"/></bibl></sourceDesc><profileDesc><textClass><keywords><term type=\"form\">Паэзія</term><term type=\"genre\">Верш</term></keywords></textClass><langUsage><language ident=\"be\">Беларуская</language></langUsage></profileDesc><textDesc><firstPublicationYear when=\"1929\">1929</firstPublicationYear></textDesc></fileDesc></teiHeader><body><seg type=\"epigraph\"><l type=\"ep\">Ja? konia poi?31.</l></seg><lg>Сталася здарэнне дый каля крыніцы\n",
       "У хлопца-баламута, ў сіроткі дзявіцы.\n",
       "Ясь спаткаў Марысю, што вадзіцу брала,\n",
       "Ды і ну дурыці, каб памандравала.\n",
       "«Забяры, Марыля, мамчына багацце,—\n",
       "Разам у чужыне мы дазнаем шчасця».\n",
       "«Што ж ты намаўляеш, як мне мандраваці,\n",
       "Ў доме ўсё замкнута, а ключы у маці,\n",
       "Ды і грэх вялікі мне за гэта будзе,\n",
       "Пан бог пакарае, свет увесь асудзе».\n",
       "«Ой, ключы нядоўга, дзевачка, дастаці,\n",
       "Папрасіся толькі у камору спаці.\n",
       "Людзі не пазнаюць і не будуць чуці,—\n",
       "Мы з табой здалеем на край свет умкнуці».\n",
       "Ну і збаламуціў хлопец той дзявіцу,\n",
       "Покі гаманілі, стоя ля крыніцы.\n",
       "Цёмнай ноччу ў вёсцы людзі моцна спалі,\n",
       "Ясечка з Марыляй ў свет памандравалі.\n",
       "Ведала ж Марыля ці сабе гадала,\n",
       "Што праз тры дзянёчкі Ясю абрыдала?\n",
       "Дзеўка ашуканца шчыра пакахала,\n",
       "А што ён надумаў, дык не спрачувала.\n",
       "Праз Дунай праз ціхі як пераплывалі,\n",
       "Скінуў Ясь Марылю з коніка у хвалі.\n",
       "Ускрыкнула дзяўчына ў страху, у распачы,—\n",
       "Ясь не аглянецца, ад злачынства скача.\n",
       "Нераты паблізу рыбакі стаўлялі,\n",
       "От яны нябозе ды ратунак далі.\n",
       "«Скуль, скажы, дзяўчынка, што каму зрабіла?»\n",
       "Плакала Марыля: «Я яго любіла».\n",
       "З свету баламуты каб усе спрагліся\n",
       "От за тыя слёзкі, што тут праліліся.\n",
       "</lg><seg type=\"footnotes\"><l><num>31</num><footnote>Ясь паіў каня (польск.).</footnote></l></seg></body></TEI>"
      ]
     },
     "execution_count": 2376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = '../../../parsed/003_Ян Баршчэўскі/003_0007.html'\n",
    "test2 = '../../../parsed/028_Янка Купала/028_0493.html'\n",
    "test3 = '../../../parsed/031_Максім Багдановіч/031_0012.html'\n",
    "test4 = '../../../parsed/032_Алесь Гарун/032_0016.html'\n",
    "test5 = '../../../parsed/032_Алесь Гарун/032_0028.html'\n",
    "test6 = '../../../parsed/032_Алесь Гарун/032_0147.html'\n",
    "\n",
    "genTree(getRaw(test6), meta(getRaw(test6)), test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2049,
   "id": "df2ceb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['div',\n",
       "  '\\nЦветы последние милей\\nРоскошных  первенцев полей.\\nА. Пушкін\\n',\n",
       "  {'class': ['EPIGRAPH']}],\n",
       " ['p', 'Цветы последние милей', {}],\n",
       " ['p', 'Роскошных  первенцев полей.', {}],\n",
       " ['p', 'А. Пушкін', {'class': ['sign']}],\n",
       " ['div', '', {'class': ['CLEAR']}],\n",
       " ['p', '\\xa0', {}],\n",
       " ['p', 'Плакала лета, зямлю пакідаючы;', {}],\n",
       " ['p', 'Ціха ліліся сьлязінкі на поле.', {}],\n",
       " ['p', 'Але прыгожаю восеньню яснаю', {}],\n",
       " ['p', 'Там, дзе упалі яны, вырасталі', {}]]"
      ]
     },
     "execution_count": 2049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAllTags(test3)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6624b9",
   "metadata": {},
   "source": [
    "## Generate simplified TXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e68ef2",
   "metadata": {},
   "source": [
    "Generation a simplified TXT file for NLP processing, including POS-tagging. Only verses proper are included in this file, headings, epigraphs, footnotes are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2321,
   "id": "acc6532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = genTree(getRaw('../../../parsed/028_Янка Купала/028_0493.html'), meta('../../../parsed/028_Янка Купала/028_0493.html'), '../../../parsed/028_Янка Купала/028_0493.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2314,
   "id": "5d9d8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleTxt(tree):\n",
    "    \"\"\"Generate simple TXT from <lg> only. Meta elements are omitted\"\"\"\n",
    "    \n",
    "    pmarks = '.,;:!?-–—()\\\"[]«»0123456789' # punctuation marks\n",
    "    txt = ''    \n",
    "    for lg in tree.body.find_all('lg'):\n",
    "        for char in lg.string.lower():\n",
    "            if char in pmarks:\n",
    "                continue\n",
    "            else:\n",
    "                txt += char\n",
    "        txt += '\\n'\n",
    "        \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2320,
   "id": "1dcc26b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'на поўначы сумнай у фіншчыне дзіўнай\\nракой з вадаспадам заліўся пакат\\nвуоксаю рэчка завецца у фінаў\\nіматрай завуць вадаспад\\n\\nклакочуць рагочуць іматрыны хвалі\\nна цэлыя вёрсты шумгоман стаіць\\nнем толечы каменны бераг як з сталі\\nі зараснік хвойны маўчыць\\n\\nшалее іматра між каменных глыбаў\\nза хваляю хвалю імчыць к нізіне\\nяк хмар недаступных махнатыя скібы\\nадна адну схопіць піргне\\n\\nадна з адной рынуцца ўглыб як магілу\\nтам скруцяцца ўзнімуцца клубам дугой\\nрассыплюцца пухам рассеюцца пылам\\nзноў выскачаць к небу гарой\\n\\nзірнуць ззіхануцца сыпнуцца на скалы\\nўсім дантаўскім процьмам на здзіў\\nі люнуць на волю забыўшыся шалаў\\nплывуць паміж пустак і ніў\\n\\nдругія іх зменяць і пеняцца ў зломе\\nадвечністым шумам калышуць прастор\\nсвабодай сваёю і роднай суомі\\nсягнуць быццам хочуць да зор\\n\\nстаіш і глядзіш на бунтоўныя воды\\nі сэрца лялеецца ў сцішнай жальбе\\nўсё слухаеш нема як стогнуць нягодай\\nды як бы ўсё клічуць цябе\\n\\nхадзі к нам бяспутнік кінь долю на свеце\\nспачын векавечны дамо ў забыцці\\nнязведанай воляю будзем шумеці\\nі гутарку з сонцам вясці\\n\\nхадзі ў нашы хвалі спаўём твае грудзі\\nвадзіцай сцюдзёнай кіпучай як вар\\nнарод аб нас казку злажыць не забудзе\\nі песню нам зложыць пясняр\\n\\nтак сумна на поўначы ў фіншчыне дзіўнай\\nракой з вадаспадам заліўся пакат\\nвуоксаю рэчка завецца у фінаў\\nіматрай завуць вадаспад\\n\\n'"
      ]
     },
     "execution_count": 2320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleTxt(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "id": "8aec2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../simplified.txt', 'w') as s:\n",
    "    s.write(simpleTxt(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ee5e2",
   "metadata": {},
   "source": [
    "## POS-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4310f787",
   "metadata": {},
   "source": [
    "Tagging is done by UDPipe/UFAL with the use of [UD Belarusian HSE](https://github.com/UniversalDependencies/UD_Belarusian-HSE) tagger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "1f5394d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "424e9291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'udpipe' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ufal/udpipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "7f8f5d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nemkovich/Studies/HSE/BPCorpus/_convert/udpipe/src\n",
      "clang++ -o .build/udpipe.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c udpipe.cpp\n",
      "clang++ -o .build/utils-options.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c utils/options.cpp\n",
      "clang++ -o .build/morphodita-derivator-derivation_formatter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/derivator/derivation_formatter.cpp\n",
      "clang++ -o .build/morphodita-derivator-derivator_dictionary.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/derivator/derivator_dictionary.cpp\n",
      "clang++ -o .build/morphodita-morpho-czech_morpho.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/czech_morpho.cpp\n",
      "clang++ -o .build/morphodita-morpho-english_morpho.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/english_morpho.cpp\n",
      "clang++ -o .build/morphodita-morpho-english_morpho_guesser.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/english_morpho_guesser.cpp\n",
      "clang++ -o .build/morphodita-morpho-external_morpho.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/external_morpho.cpp\n",
      "clang++ -o .build/morphodita-morpho-generic_morpho.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/generic_morpho.cpp\n",
      "clang++ -o .build/morphodita-morpho-morpho.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/morpho.cpp\n",
      "clang++ -o .build/morphodita-morpho-morpho_statistical_guesser.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/morpho_statistical_guesser.cpp\n",
      "clang++ -o .build/morphodita-morpho-tag_filter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/tag_filter.cpp\n",
      "clang++ -o .build/morphodita-tagger-tagger.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tagger/tagger.cpp\n",
      "clang++ -o .build/morphodita-tagset_converter-identity_tagset_converter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tagset_converter/identity_tagset_converter.cpp\n",
      "clang++ -o .build/morphodita-tagset_converter-pdt_to_conll2009_tagset_converter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tagset_converter/pdt_to_conll2009_tagset_converter.cpp\n",
      "clang++ -o .build/morphodita-tagset_converter-strip_lemma_comment_tagset_converter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tagset_converter/strip_lemma_comment_tagset_converter.cpp\n",
      "clang++ -o .build/morphodita-tagset_converter-strip_lemma_id_tagset_converter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tagset_converter/strip_lemma_id_tagset_converter.cpp\n",
      "clang++ -o .build/morphodita-tagset_converter-tagset_converter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tagset_converter/tagset_converter.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-czech_tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/czech_tokenizer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-english_tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/english_tokenizer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-generic_tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/generic_tokenizer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-ragel_tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/ragel_tokenizer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/tokenizer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-unicode_tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/unicode_tokenizer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-vertical_tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/vertical_tokenizer.cpp\n",
      "clang++ -o .build/morphodita-version-version.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/version/version.cpp\n",
      "clang++ -o .build/parsito-configuration-configuration.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/configuration/configuration.cpp\n",
      "clang++ -o .build/parsito-configuration-node_extractor.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/configuration/node_extractor.cpp\n",
      "clang++ -o .build/parsito-configuration-value_extractor.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/configuration/value_extractor.cpp\n",
      "clang++ -o .build/parsito-embedding-embedding.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/embedding/embedding.cpp\n",
      "clang++ -o .build/parsito-network-neural_network.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/network/neural_network.cpp\n",
      "clang++ -o .build/parsito-parser-parser.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/parser/parser.cpp\n",
      "clang++ -o .build/parsito-parser-parser_nn.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/parser/parser_nn.cpp\n",
      "clang++ -o .build/parsito-transition-transition.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/transition/transition.cpp\n",
      "clang++ -o .build/parsito-transition-transition_system.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/transition/transition_system.cpp\n",
      "clang++ -o .build/parsito-transition-transition_system_link2.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/transition/transition_system_link2.cpp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clang++ -o .build/parsito-transition-transition_system_projective.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/transition/transition_system_projective.cpp\n",
      "clang++ -o .build/parsito-transition-transition_system_swap.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/transition/transition_system_swap.cpp\n",
      "clang++ -o .build/parsito-tree-tree.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/tree/tree.cpp\n",
      "clang++ -o .build/parsito-tree-tree_format.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/tree/tree_format.cpp\n",
      "clang++ -o .build/parsito-tree-tree_format_conllu.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/tree/tree_format_conllu.cpp\n",
      "clang++ -o .build/parsito-version-version.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/version/version.cpp\n",
      "clang++ -o .build/unilib-unicode.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c unilib/unicode.cpp\n",
      "clang++ -o .build/unilib-utf8.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c unilib/utf8.cpp\n",
      "clang++ -o .build/unilib-version.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c unilib/version.cpp\n",
      "clang++ -o .build/utils-compressor_load.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c utils/compressor_load.cpp\n",
      "clang++ -o .build/model-evaluator.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c model/evaluator.cpp\n",
      "clang++ -o .build/model-model.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c model/model.cpp\n",
      "clang++ -o .build/model-model_morphodita_parsito.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c model/model_morphodita_parsito.cpp\n",
      "clang++ -o .build/model-pipeline.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c model/pipeline.cpp\n",
      "clang++ -o .build/morphodita-morpho-generic_morpho_encoder.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/generic_morpho_encoder.cpp\n",
      "clang++ -o .build/morphodita-morpho-morpho_statistical_guesser_encoder.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/morpho_statistical_guesser_encoder.cpp\n",
      "clang++ -o .build/morphodita-morpho-morpho_statistical_guesser_trainer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/morpho_statistical_guesser_trainer.cpp\n",
      "clang++ -o .build/morphodita-morpho-raw_morpho_dictionary_reader.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/morpho/raw_morpho_dictionary_reader.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-czech_tokenizer_factory.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/czech_tokenizer_factory.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-czech_tokenizer_factory_encoder.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/czech_tokenizer_factory_encoder.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-generic_tokenizer_factory.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/generic_tokenizer_factory.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-generic_tokenizer_factory_encoder.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/generic_tokenizer_factory_encoder.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-gru_tokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/gru_tokenizer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-gru_tokenizer_factory.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/gru_tokenizer_factory.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-gru_tokenizer_network.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/gru_tokenizer_network.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-gru_tokenizer_trainer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/gru_tokenizer_trainer.cpp\n",
      "clang++ -o .build/morphodita-tokenizer-tokenizer_factory.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c morphodita/tokenizer/tokenizer_factory.cpp\n",
      "clang++ -o .build/parsito-embedding-embedding_encode.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/embedding/embedding_encode.cpp\n",
      "clang++ -o .build/parsito-network-neural_network_trainer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/network/neural_network_trainer.cpp\n",
      "clang++ -o .build/parsito-parser-parser_nn_trainer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c parsito/parser/parser_nn_trainer.cpp\n",
      "clang++ -o .build/sentence-input_format.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c sentence/input_format.cpp\n",
      "clang++ -o .build/sentence-output_format.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c sentence/output_format.cpp\n",
      "clang++ -o .build/sentence-sentence.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c sentence/sentence.cpp\n",
      "clang++ -o .build/sentence-token.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c sentence/token.cpp\n",
      "clang++ -o .build/tokenizer-detokenizer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c tokenizer/detokenizer.cpp\n",
      "clang++ -o .build/tokenizer-morphodita_tokenizer_wrapper.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c tokenizer/morphodita_tokenizer_wrapper.cpp\n",
      "clang++ -o .build/tokenizer-multiword_splitter.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c tokenizer/multiword_splitter.cpp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clang++ -o .build/tokenizer-multiword_splitter_trainer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c tokenizer/multiword_splitter_trainer.cpp\n",
      "clang++ -o .build/trainer-trainer.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c trainer/trainer.cpp\n",
      "clang++ -o .build/trainer-trainer_morphodita_parsito.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c trainer/trainer_morphodita_parsito.cpp\n",
      "clang++ -o .build/trainer-training_failure.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c trainer/training_failure.cpp\n",
      "clang++ -o .build/unilib-uninorms.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c unilib/uninorms.cpp\n",
      "clang++ -o .build/utils-compressor_save.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c utils/compressor_save.cpp\n",
      "clang++ -o .build/version-version.osx-clang-normal.o -MMD -MP -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. -c version/version.cpp\n",
      "clang++ -o udpipe -std=c++11 -W -Wall -mtune=generic -fvisibility=hidden -mmacosx-version-min=10.7 -stdlib=libc++ -O3 -I. .build/udpipe.osx-clang-normal.o .build/utils-options.osx-clang-normal.o .build/morphodita-derivator-derivation_formatter.osx-clang-normal.o .build/morphodita-derivator-derivator_dictionary.osx-clang-normal.o .build/morphodita-morpho-czech_morpho.osx-clang-normal.o .build/morphodita-morpho-english_morpho.osx-clang-normal.o .build/morphodita-morpho-english_morpho_guesser.osx-clang-normal.o .build/morphodita-morpho-external_morpho.osx-clang-normal.o .build/morphodita-morpho-generic_morpho.osx-clang-normal.o .build/morphodita-morpho-morpho.osx-clang-normal.o .build/morphodita-morpho-morpho_statistical_guesser.osx-clang-normal.o .build/morphodita-morpho-tag_filter.osx-clang-normal.o .build/morphodita-tagger-tagger.osx-clang-normal.o .build/morphodita-tagset_converter-identity_tagset_converter.osx-clang-normal.o .build/morphodita-tagset_converter-pdt_to_conll2009_tagset_converter.osx-clang-normal.o .build/morphodita-tagset_converter-strip_lemma_comment_tagset_converter.osx-clang-normal.o .build/morphodita-tagset_converter-strip_lemma_id_tagset_converter.osx-clang-normal.o .build/morphodita-tagset_converter-tagset_converter.osx-clang-normal.o .build/morphodita-tokenizer-czech_tokenizer.osx-clang-normal.o .build/morphodita-tokenizer-english_tokenizer.osx-clang-normal.o .build/morphodita-tokenizer-generic_tokenizer.osx-clang-normal.o .build/morphodita-tokenizer-ragel_tokenizer.osx-clang-normal.o .build/morphodita-tokenizer-tokenizer.osx-clang-normal.o .build/morphodita-tokenizer-unicode_tokenizer.osx-clang-normal.o .build/morphodita-tokenizer-vertical_tokenizer.osx-clang-normal.o .build/morphodita-version-version.osx-clang-normal.o .build/parsito-configuration-configuration.osx-clang-normal.o .build/parsito-configuration-node_extractor.osx-clang-normal.o .build/parsito-configuration-value_extractor.osx-clang-normal.o .build/parsito-embedding-embedding.osx-clang-normal.o .build/parsito-network-neural_network.osx-clang-normal.o .build/parsito-parser-parser.osx-clang-normal.o .build/parsito-parser-parser_nn.osx-clang-normal.o .build/parsito-transition-transition.osx-clang-normal.o .build/parsito-transition-transition_system.osx-clang-normal.o .build/parsito-transition-transition_system_link2.osx-clang-normal.o .build/parsito-transition-transition_system_projective.osx-clang-normal.o .build/parsito-transition-transition_system_swap.osx-clang-normal.o .build/parsito-tree-tree.osx-clang-normal.o .build/parsito-tree-tree_format.osx-clang-normal.o .build/parsito-tree-tree_format_conllu.osx-clang-normal.o .build/parsito-version-version.osx-clang-normal.o .build/unilib-unicode.osx-clang-normal.o .build/unilib-utf8.osx-clang-normal.o .build/unilib-version.osx-clang-normal.o .build/utils-compressor_load.osx-clang-normal.o .build/model-evaluator.osx-clang-normal.o .build/model-model.osx-clang-normal.o .build/model-model_morphodita_parsito.osx-clang-normal.o .build/model-pipeline.osx-clang-normal.o .build/morphodita-morpho-generic_morpho_encoder.osx-clang-normal.o .build/morphodita-morpho-morpho_statistical_guesser_encoder.osx-clang-normal.o .build/morphodita-morpho-morpho_statistical_guesser_trainer.osx-clang-normal.o .build/morphodita-morpho-raw_morpho_dictionary_reader.osx-clang-normal.o .build/morphodita-tokenizer-czech_tokenizer_factory.osx-clang-normal.o .build/morphodita-tokenizer-czech_tokenizer_factory_encoder.osx-clang-normal.o .build/morphodita-tokenizer-generic_tokenizer_factory.osx-clang-normal.o .build/morphodita-tokenizer-generic_tokenizer_factory_encoder.osx-clang-normal.o .build/morphodita-tokenizer-gru_tokenizer.osx-clang-normal.o .build/morphodita-tokenizer-gru_tokenizer_factory.osx-clang-normal.o .build/morphodita-tokenizer-gru_tokenizer_network.osx-clang-normal.o .build/morphodita-tokenizer-gru_tokenizer_trainer.osx-clang-normal.o .build/morphodita-tokenizer-tokenizer_factory.osx-clang-normal.o .build/parsito-embedding-embedding_encode.osx-clang-normal.o .build/parsito-network-neural_network_trainer.osx-clang-normal.o .build/parsito-parser-parser_nn_trainer.osx-clang-normal.o .build/sentence-input_format.osx-clang-normal.o .build/sentence-output_format.osx-clang-normal.o .build/sentence-sentence.osx-clang-normal.o .build/sentence-token.osx-clang-normal.o .build/tokenizer-detokenizer.osx-clang-normal.o .build/tokenizer-morphodita_tokenizer_wrapper.osx-clang-normal.o .build/tokenizer-multiword_splitter.osx-clang-normal.o .build/tokenizer-multiword_splitter_trainer.osx-clang-normal.o .build/trainer-trainer.osx-clang-normal.o .build/trainer-trainer_morphodita_parsito.osx-clang-normal.o .build/trainer-training_failure.osx-clang-normal.o .build/unilib-uninorms.osx-clang-normal.o .build/utils-compressor_save.osx-clang-normal.o .build/version-version.osx-clang-normal.o  \n"
     ]
    }
   ],
   "source": [
    "%cd ./udpipe/src\n",
    "!make "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2429,
   "id": "c718588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagger file to be used for processing\n",
    "tagger = '../../tagger/be-ud-2.7-tagger-20210115.udpipe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "6d69cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading UDPipe model: done.\n",
      "# newdoc\n",
      "# newpar\n",
      "# sent_id = 1\n",
      "# text = Гэта\n",
      "1\tГэта\tгэта\tPRON\t_\tAnimacy=Inan|Case=Nom|Gender=Neut|Number=Sing|PronType=Dem\t_\t_\t_\tSpacesAfter=\\n\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!echo \"Гэта\" | ./udpipe --tokenize --tag '../../tagger/be-ud-2.7-tagger-20210115.udpipe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "74bff0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = subprocess.check_output([\"./udpipe\", \"--tokenize\", \"--tag\", tagger], input=txt[0], text=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "399d44b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# newdoc\\n# newpar\\n# sent_id = 1\\n# text = На поўначы сумнай, у Фіншчыне дзіўнай, Ракой з вадаспадам заліўся пакат; Вуоксаю рэчка завецца у фінаў, Іматрай завуць вадаспад.\\n1\\tНа\\tна\\tADP\\tIN\\t_\\t_\\t_\\t_\\t_\\n2\\tпоўначы\\tпоўнач\\tNOUN\\tNN\\tAnimacy=Inan|Case=Loc|Gender=Fem|Number=Sing\\t_\\t_\\t_\\t_\\n3\\tсумнай\\tсумны\\tADJ\\tJJL\\tCase=Gen|Degree=Pos|Gender=Fem|Number=Sing\\t_\\t_\\t_\\tSpaceAfter=No\\n4\\t,\\t,\\tPUNCT\\tPUNCT\\t_\\t_\\t_\\t_\\t_\\n5\\tу\\tу\\tADP\\tIN\\t_\\t_\\t_\\t_\\t_\\n6\\tФіншчыне\\tФіншчына\\tPROPN\\tNNP\\tAnimacy=Inan|Case=Loc|Gender=Fem|Number=Sing\\t_\\t_\\t_\\t_\\n7\\tдзіўнай\\tдзіўны\\tADJ\\tJJL\\tCase=Ins|Degree=Pos|Gender=Fem|Number=Sing\\t_\\t_\\t_\\tSpaceAfter=No\\n8\\t,\\t,\\tPUNCT\\tPUNCT\\t_\\t_\\t_\\t_\\tSpacesAfter=\\\\n\\n9\\tРакой\\tрака\\tNOUN\\tNN\\tAnimacy=Inan|Case=Ins|Gender=Fem|Number=Sing\\t_\\t_\\t_\\t_\\n10\\tз\\tз\\tADP\\tIN\\t_\\t_\\t_\\t_\\t_\\n11\\tвадаспадам\\tвадаспад\\tNOUN\\tNN\\tAnimacy=Inan|Case=Ins|Gender=Masc|Number=Sing\\t_\\t_\\t_\\t_\\n12\\tзаліўся\\tзаліцца\\tVERB\\tVBC\\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\\t_\\t_\\t_\\t_\\n13\\tпакат\\tпакат\\tNOUN\\tNN\\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\\t_\\t_\\t_\\tSpaceAfter=No\\n14\\t;\\t;\\tPUNCT\\tPUNCT\\t_\\t_\\t_\\t_\\tSpacesAfter=\\\\n\\n15\\tВуоксаю\\tВуоксы\\tVERB\\tVBC\\tAspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\\t_\\t_\\t_\\t_\\n16\\tрэчка\\tрэчка\\tNOUN\\tNN\\tAnimacy=Inan|Case=Nom|Gender=Fem|Number=Sing\\t_\\t_\\t_\\t_\\n17\\tзавецца\\tзвацца\\tVERB\\tVBC\\tAspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\\t_\\t_\\t_\\t_\\n18\\tу\\tу\\tADP\\tIN\\t_\\t_\\t_\\t_\\t_\\n19\\tфінаў\\tфіна\\tNOUN\\tNN\\tAnimacy=Inan|Case=Gen|Gender=Masc|Number=Plur\\t_\\t_\\t_\\tSpaceAfter=No\\n20\\t,\\t,\\tPUNCT\\tPUNCT\\t_\\t_\\t_\\t_\\tSpacesAfter=\\\\n\\n21\\tІматрай\\tІматра\\tNOUN\\tNN\\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\\t_\\t_\\t_\\t_\\n22\\tзавуць\\tзваць\\tVERB\\tVBC\\tAspect=Perf|Mood=Ind|Number=Plur|Person=3|Tense=Fut|VerbForm=Fin|Voice=Act\\t_\\t_\\t_\\t_\\n23\\tвадаспад\\tвадаспад\\tNOUN\\tNN\\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\\t_\\t_\\t_\\tSpaceAfter=No\\n24\\t.\\t.\\tPUNCT\\tPUNCT\\t_\\t_\\t_\\t_\\tSpacesAfter=\\\\n\\n\\n'"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea75e46",
   "metadata": {},
   "source": [
    "The output is produced in tab-separated UD [CoNLL-U format](https://universaldependencies.org/format.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1440,
   "id": "41363fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPos(text):\n",
    "    \"\"\"Transform ConNLL-U format into Python data structures\"\"\"\n",
    "    \n",
    "    output = subprocess.check_output([\"./udpipe\", \"--tokenize\", \"--tag\", tagger], input=text, text=True) \n",
    "    lemlist = [line.strip().split('\\t') for line in output.split('\\n') if '\\t' in line]\n",
    "    posTags = []\n",
    "\n",
    "    for l in lemlist:\n",
    "        if '=' in l[9]:\n",
    "            space = l[9].split('=')[1]\n",
    "        else:\n",
    "            space = None\n",
    "\n",
    "        posTags.append([l[1], l[2].lower(), l[3], l[4], l[5], space])\n",
    "        \n",
    "    return posTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "id": "2618ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['лепшы',\n",
       "  'лепшы',\n",
       "  'ADJ',\n",
       "  'ORD',\n",
       "  'Case=Nom|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  '\\\\n']]"
      ]
     },
     "execution_count": 1442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPos('лепшы')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2316,
   "id": "945d26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posTag(tree):\n",
    "    \"\"\"Tokenize previously generated simple tree and populate it with POS tags\"\"\"\n",
    "    \n",
    "    newtree = tree\n",
    "    lgStr = ''\n",
    "    lgs = [lg for lg in tree.body.find_all_next('lg')]\n",
    "    \n",
    "    for lg in lgs: \n",
    "        lgStr += lg.string + '\\n\\n'\n",
    "        \n",
    "    posTags = getPos(lgStr)\n",
    "    \n",
    "    posLgs = [] #stanza list\n",
    "    posLg = [] #stanza\n",
    "    posL = [] #single line\n",
    "    \n",
    "    for pos in posTags:         \n",
    "        if pos[5] == '\\\\n':\n",
    "            posL.append([pos[0], pos[1], pos[2], pos[3], pos[4], None])\n",
    "            posLg.append(posL)\n",
    "            posL = []\n",
    "            \n",
    "        elif pos[5] == '\\\\n\\\\n\\\\n':\n",
    "            posL.append([pos[0], pos[1], pos[2], pos[3], pos[4], None])\n",
    "            posLg.append(posL)\n",
    "            posLgs.append(posLg)\n",
    "            posL = []\n",
    "            posLg = []\n",
    "            \n",
    "        else:\n",
    "            posL.append(pos)\n",
    "            \n",
    "    if len(posLgs) == len(lgs):        \n",
    "\n",
    "        for i,lg in enumerate(lgs):\n",
    "            lg.string = ''\n",
    "            \n",
    "            for posTags in posLgs[i]:\n",
    "                \n",
    "                line = newtree.new_tag('l')\n",
    "\n",
    "                for pos in posTags:                     \n",
    "                    if pos[2] == 'PUNCT':\n",
    "                        pc = newtree.new_tag('pc')\n",
    "                        pc.string = pos[0]\n",
    "                        \n",
    "                        if pos[5]:\n",
    "                            if 'No' in pos[5]: \n",
    "                                pc['join'] = 'right'\n",
    "                        \n",
    "                        line.append(pc)\n",
    "\n",
    "                    else:\n",
    "                        dig = re.search('(?=[\\w]*)\\d{1,2}', pos[0])\n",
    "                        if not dig:\n",
    "                            w = newtree.new_tag('w')\n",
    "                            w.string = pos[0]\n",
    "                            w['lemma'] = pos[1]\n",
    "                            w['pos'] = pos[2]\n",
    "                            w['ppos'] = pos[3]\n",
    "                            if pos[4] != '_':\n",
    "                                w['msd'] = pos[4]\n",
    "\n",
    "                            if pos[5]:\n",
    "                                if 'No' in pos[5]: \n",
    "                                    w['join'] = 'right'\n",
    "                                    \n",
    "                            line.append(w)\n",
    "                                    \n",
    "                        else:\n",
    "                            s = newtree.new_tag('sup')\n",
    "                            s.string = dig.group()\n",
    "                            \n",
    "                            w = newtree.new_tag('w')\n",
    "                            w.string = pos[0].replace(dig.group(),'')\n",
    "                            w['lemma'] = pos[0].replace(dig.group(),'')\n",
    "                            w['pos'] = pos[2]\n",
    "                            w['ppos'] = pos[3]\n",
    "                            if pos[4] != '_':\n",
    "                                w['msd'] = pos[4]\n",
    "                                \n",
    "                            if pos[5]:\n",
    "                                if 'No' in pos[5]: \n",
    "                                    s['join'] = 'right'\n",
    "                            \n",
    "                            line.append(w)\n",
    "                            line.append(s)\n",
    "                        \n",
    "                lg.append(line)\n",
    "                    \n",
    "    \n",
    "    return newtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2318,
   "id": "2c092cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<TEI><teiHeader><fileDesc><titleStmt><author><persName/></author></titleStmt><sourceDesc><bibl type=\"digitalSource\"><ptr target=\"https://knihi.com//Uladzislau_Syrakomla/Karali.html\"/></bibl></sourceDesc><profileDesc><textClass><keywords><term type=\"form\">Паэзія</term></keywords></textClass><langUsage><language ident=\"be\">Беларуская</language></langUsage></profileDesc><textDesc/></fileDesc></teiHeader><body><seg type=\"italic\">З польскай — У. Сыракомлі</seg><lg><l><w lemma=\"як\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"WRB\">Як</w><w lemma=\"ісці\" msd=\"Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">ішоў</w><w lemma=\"я\" msd=\"Case=Nom|Number=Sing|Person=1|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">я</w><w lemma=\"у\" pos=\"ADP\" ppos=\"IN\">ў</w><w lemma=\"бы\" msd=\"Case=Loc|Degree=Pos|Gender=Fem|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">бой</w><w join=\"right\" lemma=\"кіпяча\" msd=\"Aspect=Imp|Tense=Pres|VerbForm=Conv|Voice=Act\" pos=\"VERB\" ppos=\"VBG\">кіпячы</w><pc>,</pc></l><l><w lemma=\"як\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"WRB\">Як</w><w lemma=\"прашчацца\" msd=\"Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\" pos=\"VERB\" ppos=\"VBC\">прашчаўся</w><w lemma=\"з\" pos=\"ADP\" ppos=\"IN\">з</w><w join=\"right\" lemma=\"хатка\" msd=\"Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">хаткай</w><pc>,</pc></l><l><w lemma=\"тут\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"RB\">Тут</w><w lemma=\"гануля\" msd=\"Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing\" pos=\"PROPN\" ppos=\"NNP\">Гануля</w><w lemma=\"мой\" msd=\"Case=Nom|Gender=Fem|Number=Sing|Poss=Yes|PronType=Prs\" pos=\"DET\" ppos=\"JJL\">мая</w><w lemma=\"з\" pos=\"ADP\" ppos=\"IN\">з</w><w join=\"right\" lemma=\"плач\" msd=\"Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">плачам</w><pc>:</pc></l><l><pc join=\"right\">«</pc><w lemma=\"ісцпой\" msd=\"Aspect=Perf|Mood=Ind|Number=Sing|Person=2|Tense=Fut|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">Пойдзеш</w><w join=\"right\" lemma=\"гінуць\" msd=\"Aspect=Imp|VerbForm=Inf|Voice=Act\" pos=\"VERB\" ppos=\"VB\">гінуць</w><pc>,</pc><w join=\"right\" lemma=\"братка\" msd=\"Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">братка</w><pc>!</pc></l><l><w lemma=\"але\" pos=\"CCONJ\" ppos=\"CC\">Але</w><w lemma=\"быць\" msd=\"Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\" pos=\"AUX\" ppos=\"VBC\">буду</w><w lemma=\"я\" msd=\"Case=Nom|Number=Sing|Person=1|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">я</w><w lemma=\"маліцца\" msd=\"Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\" pos=\"VERB\" ppos=\"VBC\">маліцца</w></l><l><w lemma=\"па\" pos=\"ADP\" ppos=\"_\">Па</w><w lemma=\"ты\" msd=\"Case=Dat|Number=Sing|Person=2|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">табе</w><w lemma=\"з\" pos=\"ADP\" ppos=\"IN\">з</w><w join=\"right\" lemma=\"трывога\" msd=\"Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">трывогі</w><pc>,</pc></l><l><w lemma=\"ты\" msd=\"Case=Nom|Number=Sing|Person=2|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">Ты</w><w lemma=\"ж\" pos=\"PART\" ppos=\"UH\">ж</w><w lemma=\"прынось\" msd=\"Aspect=Imp|Mood=Imp|Number=Plur|Person=2|VerbForm=Fin|Voice=Mid\" pos=\"VERB\" ppos=\"VBC\">прынось</w><w lemma=\"за\" pos=\"ADP\" ppos=\"IN\">за</w><w lemma=\"то\" msd=\"Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing|PronType=Dem\" pos=\"PRON\" ppos=\"DT\">то</w><w lemma=\"гасцінец\" msd=\"Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">гасцінца</w><pc>—</pc></l><l><w lemma=\"шнура\" msd=\"Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\" pos=\"PROPN\" ppos=\"NNP\">Шнур</w><w lemma=\"караля\" msd=\"Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">караляў</w><w join=\"right\" lemma=\"доўгі\" msd=\"Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">доўгі</w><pc join=\"right\">»</pc><pc>.</pc></l></lg><lg><l><w lemma=\"з\" pos=\"ADP\" ppos=\"IN\">З</w><w lemma=\"ласкі\" msd=\"Case=Ins|Degree=Pos|Gender=Fem|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">ласкай</w><w lemma=\"божай\" msd=\"Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">Божай</w><w lemma=\"паручыць\" msd=\"Aspect=Perf|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">паручыла</w></l><l><w lemma=\"грамада\" msd=\"Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">Грамадзе</w><w join=\"right\" lemma=\"радзіма\" msd=\"Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">радзімай</w><pc>:</pc></l><l><w lemma=\"пасці\" msd=\"Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">Палі</w><w lemma=\"ворагавы\" msd=\"Animacy=Inan|Case=Nom|Gender=Fem|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">ворагавы</w><w join=\"right\" lemma=\"сіла\" msd=\"Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">сілы</w><pc>,</pc></l><l><w lemma=\"горад\" msd=\"Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">Горад</w><w lemma=\"здабыць\" msd=\"Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">здабылі</w><w join=\"right\" lemma=\"мы\" msd=\"Case=Nom|Number=Plur|Person=1|PronType=Prs\" pos=\"PRON\" ppos=\"_\">мы</w><pc>.</pc></l><l><w lemma=\"як\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"WRB\">Як</w><w lemma=\"прыціхнуць\" msd=\"Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">прыціхнулі</w><w join=\"right\" lemma=\"гармат\" msd=\"Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">гарматы</w><pc>,</pc></l><l><w lemma=\"як\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"WRB\">Як</w><w lemma=\"брама\" msd=\"Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">браму</w><w join=\"right\" lemma=\"зламаць\" msd=\"Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">зламалі</w><pc>,</pc></l><l><w lemma=\"хто\" msd=\"Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing|PronType=Int\" pos=\"PRON\" ppos=\"_\">Хто</w><w join=\"right\" lemma=\"саетаць\" msd=\"Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">саетаў</w><pc>,</pc><w lemma=\"хто\" msd=\"Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing|PronType=Int\" pos=\"PRON\" ppos=\"WP\">хто</w><w lemma=\"дукатаць\" msd=\"Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">дукатаў</w><pc>—</pc></l><l><w lemma=\"я\" msd=\"Case=Nom|Number=Sing|Person=1|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">Я</w><w lemma=\"шукаць\" msd=\"Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">шукаў</w><w join=\"right\" lemma=\"караля\" msd=\"Animacy=Anim|Case=Acc|Gender=Masc|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">караляў</w><pc>.</pc></l></lg><lg><l><w lemma=\"хоць\" pos=\"PART\" ppos=\"UH\">Хоць</w><w lemma=\"і\" pos=\"PART\" ppos=\"UH\">і</w><w lemma=\"у\" pos=\"ADP\" ppos=\"IN\">ў</w><w lemma=\"шчасці\" msd=\"Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">шчасці</w><w lemma=\"не\" msd=\"Polarity=Neg\" pos=\"PART\" ppos=\"UH\">не</w><w join=\"right\" lemma=\"радзіцца\" msd=\"Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\" pos=\"VERB\" ppos=\"VBC\">радзіўся</w><pc>,</pc></l><l><w lemma=\"а\" pos=\"CCONJ\" ppos=\"CC\">А</w><w lemma=\"шукаць\" msd=\"Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">шукаю</w><w join=\"right\" lemma=\"смела\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"RB\">смела</w><pc>...</pc></l><l><w lemma=\"шнура\" msd=\"Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\" pos=\"PROPN\" ppos=\"NNP\">Шнур</w><w lemma=\"караля\" msd=\"Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">караляў</w><w join=\"right\" lemma=\"замігціцца\" msd=\"Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\" pos=\"VERB\" ppos=\"VBC\">замігціўся</w><pc>,</pc></l><l><w lemma=\"як\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"WRB\">Як</w><w lemma=\"бы\" msd=\"Mood=Cnd\" pos=\"SCONJ\" ppos=\"IN\">бы</w><w lemma=\"вішань\" msd=\"Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">вішань</w><w join=\"right\" lemma=\"спелы\" msd=\"Case=Gen|Degree=Pos|Number=Plur\" pos=\"ADJ\" ppos=\"JJL\">спелых</w><pc>.</pc></l><l><w lemma=\"тут\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"RB\">Тут</w><w lemma=\"здабычына\" msd=\"Animacy=Anim|Case=Acc|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">здабычыну</w><w join=\"right\" lemma=\"схапісці\" msd=\"Aspect=Perf|Tense=Past|VerbForm=Conv|Voice=Act\" pos=\"VERB\" ppos=\"VBG\">схапіўшы</w><pc>,</pc></l><l><w lemma=\"не\" msd=\"Polarity=Neg\" pos=\"PART\" ppos=\"UH\">Не</w><w lemma=\"чакаць\" msd=\"Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">чакаю</w><w join=\"right\" lemma=\"далей\" msd=\"Degree=Cmp\" pos=\"ADV\" ppos=\"RB\">далей</w><pc>.</pc></l><l><w lemma=\"чым\" msd=\"Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing|PronType=Int\" pos=\"PRON\" ppos=\"WP\">Чым</w><w lemma=\"хутка\" msd=\"Degree=Cmp\" pos=\"ADV\" ppos=\"RBR\">хутчэй</w><w lemma=\"спяш\" msd=\"Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">спяшу</w><w lemma=\"к\" pos=\"ADP\" ppos=\"IN\">к</w><w lemma=\"наймільшы\" msd=\"Case=Dat|Degree=Cmp|Gender=Fem|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">наймільшай</w><pc>—</pc></l><l><w lemma=\"даць\" msd=\"Aspect=Imp|VerbForm=Inf|Voice=Act\" pos=\"VERB\" ppos=\"VB\">Даць</w><w lemma=\"яна\" msd=\"Case=Dat|Gender=Fem|Number=Sing|Person=3|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">ёй</w><w lemma=\"шнура\" msd=\"Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">шнур</w><w join=\"right\" lemma=\"караля\" msd=\"Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">караляў</w><pc>.</pc></l></lg><lg><l><w lemma=\"па\" pos=\"ADP\" ppos=\"_\">Па</w><w join=\"right\" lemma=\"гасцінец\" msd=\"Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">гасцінцы</w><pc>,</pc><w lemma=\"па\" pos=\"ADP\" ppos=\"IN\">па</w><w lemma=\"дарожка\" msd=\"Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">дарожцы</w></l><l><w lemma=\"кульгаць\" msd=\"Animacy=Anim|Case=Dat|Gender=Masc|Number=Sing\" pos=\"PROPN\" ppos=\"NNP\">Кульгаю</w><w join=\"right\" lemma=\"дадому\" msd=\"Case=Dat|Degree=Pos|Gender=Masc|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">дадому</w><pc>...</pc></l><l><w lemma=\"загудзець\" msd=\"Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">Загудзелі</w><w lemma=\"зваць\" msd=\"Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">званы</w><w lemma=\"у\" pos=\"ADP\" ppos=\"IN\">ў</w><w join=\"right\" lemma=\"вёска\" msd=\"Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">вёсцы</w><pc>,</pc></l><l><w lemma=\"як\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"WRB\">Як</w><w lemma=\"па\" pos=\"ADP\" ppos=\"IN\">па</w><w join=\"right\" lemma=\"нежывы\" msd=\"Case=Dat|Degree=Pos|Gender=Masc|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">нежывому</w><pc>.</pc></l><l><w lemma=\"прыбліжацца\" msd=\"Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Mid\" pos=\"VERB\" ppos=\"VBC\">Прыбліжаюся</w><w lemma=\"к\" pos=\"ADP\" ppos=\"IN\">к</w><w join=\"right\" lemma=\"хаціна\" msd=\"Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">хаціне</w><pc>,</pc></l><l><w lemma=\"аж\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"RB\">Аж</w><w lemma=\"тут\" msd=\"Degree=Pos\" pos=\"ADV\" ppos=\"RB\">тут</w><w lemma=\"чалавек\" msd=\"Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">людзі</w><w join=\"right\" lemma=\"здаль\" msd=\"Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">здаля</w><pc>:</pc></l><l><pc join=\"right\">«</pc><w lemma=\"твой\" msd=\"Case=Nom|Degree=Pos|Gender=Fem|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">Твая</w><w lemma=\"ганна\" msd=\"Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing\" pos=\"PROPN\" ppos=\"NNP\">Ганна</w><w lemma=\"у\" pos=\"ADP\" ppos=\"IN\">ў</w><w join=\"right\" lemma=\"дамавіна\" msd=\"Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">дамавіне</w><pc join=\"right\">,</pc><pc>—</pc></l><l><w lemma=\"не\" msd=\"Polarity=Neg\" pos=\"PART\" ppos=\"UH\">Не</w><w lemma=\"трэба\" pos=\"VERB\" ppos=\"PRED\">трэба</w><w join=\"right\" lemma=\"караля\" msd=\"Animacy=Anim|Case=Acc|Gender=Masc|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">караляў</w><pc join=\"right\">!</pc><pc>»</pc></l></lg><lg><l><w join=\"right\" lemma=\"ой\" pos=\"INTJ\" ppos=\"_\">Ой</w><pc>,</pc><w join=\"right\" lemma=\"заплакаць\" msd=\"Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">заплакаў</w><pc>,</pc><w join=\"right\" lemma=\"ой\" pos=\"INTJ\" ppos=\"_\">ой</w><pc>,</pc><w join=\"right\" lemma=\"заенчыць\" msd=\"Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">заенчыў</w><pc>,</pc></l><l><w lemma=\"цяжэй\" msd=\"Degree=Cmp\" pos=\"ADV\" ppos=\"RBR\">Цяжэй</w><w lemma=\"цяжкі\" msd=\"Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">цяжкай</w><w join=\"right\" lemma=\"хмара\" msd=\"Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">хмары</w><pc>,</pc></l><l><w lemma=\"перад\" pos=\"ADP\" ppos=\"IN\">Перад</w><w lemma=\"цэркаўка\" msd=\"Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">цэркаўкай</w><w join=\"right\" lemma=\"укленчыць\" msd=\"Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">укленчыў</w><pc>,</pc></l><l><w lemma=\"ды\" pos=\"CCONJ\" ppos=\"CC\">Дый</w><w lemma=\"спяш\" msd=\"Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">спяшу</w><w lemma=\"корпус\" pos=\"ADP\" ppos=\"IN\">к</w><w join=\"right\" lemma=\"алтар\" msd=\"Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">алтару</w><pc>;</pc></l><l><w lemma=\"да\" pos=\"ADP\" ppos=\"IN\">Да</w><w lemma=\"свяцейшы\" msd=\"Case=Gen|Degree=Sup|Gender=Fem|Number=Sing\" pos=\"ADJ\" ppos=\"JJL\">свяцейшай</w><w lemma=\"да\" pos=\"ADP\" ppos=\"IN\">да</w><w lemma=\"марыя\" msd=\"Animacy=Anim|Case=Gen|Gender=Fem|Number=Sing\" pos=\"PROPN\" ppos=\"NNP\">Марыі</w></l><l><w lemma=\"збліжацца\" msd=\"Aspect=Imp|Mood=Ind|Number=Sing|Person=1|Tense=Pres|VerbForm=Fin|Voice=Mid\" pos=\"VERB\" ppos=\"VBC\">Збліжаюся</w><w lemma=\"у\" pos=\"ADP\" ppos=\"IN\">ў</w><w join=\"right\" lemma=\"жаль\" msd=\"Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">жалі</w><pc>,</pc></l><l><w lemma=\"і\" pos=\"CCONJ\" ppos=\"CC\">І</w><w lemma=\"завесіць\" msd=\"Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\" pos=\"VERB\" ppos=\"VBC\">завесіў</w><w lemma=\"яна\" msd=\"Case=Ins|Gender=Fem|Number=Sing|Person=3|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">ёй</w><w lemma=\"на\" pos=\"ADP\" ppos=\"IN\">на</w><w lemma=\"шыя\" msd=\"Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">шыі</w></l><l><w lemma=\"той\" msd=\"Case=Gen|Degree=Pos|Number=Plur\" pos=\"ADJ\" ppos=\"JJL\">Тых</w><w lemma=\"я\" msd=\"Case=Nom|Number=Sing|Person=1|PronType=Prs\" pos=\"PRON\" ppos=\"PRP\">я</w><w lemma=\"шнура\" msd=\"Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\" pos=\"NOUN\" ppos=\"NN\">шнур</w><w join=\"right\" lemma=\"караля\" msd=\"Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\" pos=\"NOUN\" ppos=\"NN\">караляў</w><pc>.</pc></l></lg><seg type=\"timestamp\">[1911-1912?]</seg></body></TEI>"
      ]
     },
     "execution_count": 2318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpath = '../../../parsed/013_Уладзіслаў Сыракомля/013_0004.html'\n",
    "testtree = posTag(genTree(getRaw(tpath), meta(tpath), tpath))\n",
    "testtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2319,
   "id": "93afefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../../postest.xml', 'w') as s:\n",
    "    s.write(str(testtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370848b9",
   "metadata": {},
   "source": [
    "## Generate search index string\n",
    "Index string is the text that will be stored in FTS5 virtual table in database for search purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "id": "5716957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath = '../../../parsed/028_Янка Купала/028_0493.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "id": "57ba1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "testtree = posTag(genTree(inpath)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1820,
   "id": "dd7e5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchInd(fulltree):\n",
    "    \"\"\"Collect tokens and lemmas\"\"\"\n",
    "    indexList = []\n",
    "    \n",
    "    for w in fulltree.body.find_all(['w']):\n",
    "        if w.string:\n",
    "            token = w.string.lower()\n",
    "            if w['lemma']:\n",
    "                lemma = w['lemma'].lower()\n",
    "                indexList.extend([token, lemma])\n",
    "\n",
    "            else:\n",
    "                indexList.extend(token)\n",
    "\n",
    "    indexString = ' '.join(set(indexList))      \n",
    "    return indexString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "id": "6e20b5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'заліцца цябе бераг глядзіш дзіўнай нас не спаўём рассеюцца казка сцішнай іматр свеце свабодай цэлыя фіншчына клакокаць нізіне бунтоўныя ў ды воляю другі кінь небу зложыць клічуць забыццё сонцам за скібы піргнуць бы долю сягнуць скруціцца стаіць зваць хвалі мы свабода адвечністым ўсё рака стаіш вясць кіпучай схопіць рынуцца да зора хмар неба быць вадзіца рассецца вёрст дзіўны нем толечы вёрсты магіла ніў ззіхануцца слухаеш глыбаў прастор вуоксаю глядзіць клікаць люнуць забыўшыся нам скруцяцца шала злажыць змяніць ніва процьм вада шум забыцці іх каменных будзем хвалю хмара зор твае на усё між цэлы шумам калысаць ўсім дантаўскі маўчаць роднай процьмам гутарка жальбе рассыплюцца іматрыны зломе бунтоўны суомі вадаспад песню пылам сцюдзёнай кіпучая шалее векавечны дам хадзець як звацца свет калышуць іматра народ завуць дамо вадзіцай хадзі гарой сцішны адзін сумнай нашы клуб пясняр скіба фінаў сыпнуцца грудзі лялеецца каменны і шалаў сцюдзёны адну зараснік клубам там быццам доля сваёя сталь гутарку недаступных рагочуць ракой глыба ўглыб выскачаць рагокаць плывуць пеняцца пакат забыць воды дугой махнатыя песня заліўся скал сталі увесь грудзь клакочуць шумеці скалы недаступны сваёю ты адвечністы яны нізіна к хацець вуоксы волю рэчка зменяць хочуць нязведанай маўчыць пухам сумна хадзіць кінуць дуга лялецца другія вар нязведаны паміж гара родны вясці хваляю казку аб нягода фіншчыне магілу злом слухаць завецца наш сонца у імчыць махнаты сумны піргне пыл здзіў пеніцца жальба адной іматрай пух спачын фіна іматрын рассыплцца пустка зірнуць зноў дантаўскім забудзе сэрца шумець поўнач адна з забыцца хваля хвойны стогнуць стаяць бяспутнік вадаспадам шум-гоман нь прастора нема спаўё воля нягодай так ўзнімуцца твой пустак поўначы'"
      ]
     },
     "execution_count": 1821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchInd(testtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaed92e",
   "metadata": {},
   "source": [
    "## Generate HTML for website view\n",
    "New HTML markups includes styling of semantic elements and POS-tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "id": "a916aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkHtml(tree):\n",
    "    \"\"\"Generate HTML for website viewing\"\"\"\n",
    "\n",
    "    htmltree = BeautifulSoup('', 'html')\n",
    "\n",
    "    for i,item in enumerate(tree.body.find_all(['lg', 'seg'])):\n",
    "\n",
    "        br = htmltree.new_tag('br')\n",
    "\n",
    "        if item.name == 'lg':  \n",
    "            st = htmltree.new_tag('span')\n",
    "            st['class'] = 'stanza'\n",
    "            st.string = ''\n",
    "\n",
    "            for line in item.find_all('l'):\n",
    "                p = htmltree.new_tag('p')\n",
    "                p.string = ''\n",
    "\n",
    "                for token in line.find_all():\n",
    "                    ssp = htmltree.new_tag('span')\n",
    "                    ssp['class'] = 'space'\n",
    "                    ssp.string = ' '\n",
    "\n",
    "                    if token.name == 'w':\n",
    "                        wsp = htmltree.new_tag('span')\n",
    "                        wsp.string = token.text\n",
    "                        wsp['class'] = 'token'\n",
    "                        wsp['title'] = ' '.join(token.attrs.values())\n",
    "                        p.append(wsp)\n",
    "\n",
    "                        if 'join' not in token.attrs:\n",
    "                            p.append(ssp)\n",
    "\n",
    "\n",
    "                    elif token.name == 'pc':\n",
    "                        psp = htmltree.new_tag('span')\n",
    "                        psp.string = token.text\n",
    "                        psp['class'] = 'pc'\n",
    "                        p.append(psp)\n",
    "\n",
    "                        if 'join' not in token.attrs:\n",
    "                            p.append(ssp)\n",
    "\n",
    "                    elif token.name == 'sup':\n",
    "                        sup = htmltree.new_tag('sup')\n",
    "                        sup.string = token.text\n",
    "                        p.append(sup)\n",
    "\n",
    "                        if 'join' not in token.attrs:\n",
    "                            p.append(ssp)\n",
    "\n",
    "                st.append(p)\n",
    "\n",
    "            htmltree.append(st)\n",
    "            htmltree.append(br)\n",
    "\n",
    "        if item.name == 'seg':\n",
    "            seg = htmltree.new_tag('span')\n",
    "\n",
    "            if 'type' in item.attrs:\n",
    "                seg['class'] = item['type']\n",
    "                \n",
    "            if seg['class'] == 'footnotes':\n",
    "                p = htmltree.new_tag('p')\n",
    "                p.string = ''\n",
    "                for item in tree.body.find_all(['num','footnote']):\n",
    "                    if item.name == 'num':\n",
    "                        sup = htmltree.new_tag('sup')\n",
    "                        sup.string = item.text\n",
    "                        p.append(sup)\n",
    "                        p.append(ssp)\n",
    "\n",
    "                    elif item.name == 'footnote':\n",
    "                        ftnt = htmltree.new_tag('span')\n",
    "                        ftnt['class'] = 'footnote'\n",
    "                        ftnt.string = item.text\n",
    "                        p.append(ftnt)\n",
    "                        seg.append(p)\n",
    "                        p = htmltree.new_tag('p')\n",
    "                        p.string = ''\n",
    "                        \n",
    "            elif seg['class'] == 'epigraph': \n",
    "                for line in item.find_all('l'):\n",
    "                    p = htmltree.new_tag('p')\n",
    "                    p.string = line.text\n",
    "                    seg.append(p)\n",
    "                \n",
    "            else:\n",
    "                seg.string = item.text\n",
    "\n",
    "            htmltree.append(seg)\n",
    "            htmltree.append(br)\n",
    "            \n",
    "    return htmltree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2014,
   "id": "6aae7ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = mkHtml(posTag(genTree('../../../parsed/019_Янка Лучына/019_0001.html')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2015,
   "id": "28bd8c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.find('span', {'class' : 'epigraph'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2016,
   "id": "ec5e521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../html2.html', 'w', encoding='utf-8') as h:\n",
    "    h.write(str(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ef85cb",
   "metadata": {},
   "source": [
    "## Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "id": "daf79a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1938,
   "id": "36133afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = '../../bpc.sqlite3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1941,
   "id": "b5da6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDb(dbfile):\n",
    "    \"\"\"Create DB\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(dbfile)\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "id": "06a9104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "createDb(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2089,
   "id": "796ea7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(dbfile):\n",
    "    \"\"\"DB connection\"\"\"\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(dbfile, isolation_level = None)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2090,
   "id": "76810879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(dbfile, sql):\n",
    "    \"\"\"Execute request\"\"\"\n",
    "    \n",
    "    cur = connect(dbfile).cursor()\n",
    "    cur.execute(sql) \n",
    "    cur.close()\n",
    "    connect(dbfile).close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2091,
   "id": "909f367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dbfile, sql):\n",
    "    \"\"\"Retrieve DB rows\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(dbfile)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql) \n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    connect(dbfile).close() \n",
    "    \n",
    "    if rows:\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c3a36",
   "metadata": {},
   "source": [
    "## Create DB tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46785619",
   "metadata": {},
   "source": [
    "### `authors` table\n",
    "\n",
    "Schema:\n",
    "- id - primary key\n",
    "- name\n",
    "- forename\n",
    "- surname\n",
    "- life_born\n",
    "- life_died\n",
    "- gender\n",
    "- wiki_url\n",
    "\n",
    "4 first values will be populated from `authDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "id": "09f74e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': {'Forename': 'Максім', 'Surname': 'Багдановіч'}, 'id': 2}"
      ]
     },
     "execution_count": 1937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authDict['Максім Багдановіч']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "id": "a4827b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schA = 'CREATE TABLE IF NOT EXISTS authors (id integer PRIMARY KEY, \\\n",
    "                                            name text NOT NULL, \\\n",
    "                                            forename text, \\\n",
    "                                            surname text, \\\n",
    "                                            life_born integer, \\\n",
    "                                            life_died integer, \\\n",
    "                                            gender integer, \\\n",
    "                                            wiki_url text);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "id": "2e305dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create authors table\n",
    "execute(dbfile, schA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1958,
   "id": "fc1c08d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id', 'INTEGER', 0, None, 1),\n",
       " (1, 'name', 'TEXT', 1, None, 0),\n",
       " (2, 'forename', 'TEXT', 0, None, 0),\n",
       " (3, 'surname', 'TEXT', 0, None, 0),\n",
       " (4, 'life_born', 'INTEGER', 0, None, 0),\n",
       " (5, 'life_died', 'INTEGER', 0, None, 0),\n",
       " (6, 'gender', 'INTEGER', 0, None, 0),\n",
       " (7, 'wiki_url', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 1958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getData(dbfile, 'PRAGMA table_info(authors)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1982,
   "id": "503ddaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': {'Forename': 'Францішак', 'Surname': 'Багушэвіч'}, 'id': 3}"
      ]
     },
     "execution_count": 1982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authDict['Францішак Багушэвіч']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1979,
   "id": "5fd286a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auTab(adict):\n",
    "    \"\"\"Populate authors table\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(dbfile, isolation_level = None)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('delete from authors') # reset table \n",
    "\n",
    "    for a in [(adict[i]['id'], i, adict[i]['name']) for i in adict.keys()]:\n",
    "        aid = a[0]\n",
    "        name = a[1]\n",
    "        if isinstance(a[2], dict):\n",
    "            forename = a[2]['Forename']\n",
    "            surname = a[2]['Surname'] \n",
    "            cur.execute('insert into authors (id, name, forename, surname) values (?, ?, ?, ?)', \\\n",
    "                        (aid, name, forename, surname))\n",
    "        else:\n",
    "            cur.execute('insert into authors (id, name) values (?, ?)', (aid, name))\n",
    "            \n",
    "    print('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "id": "d24f5155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+\n"
     ]
    }
   ],
   "source": [
    "auTab(authDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2086,
   "id": "53dfadd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'Францішак Багушэвіч', 'Францішак', 'Багушэвіч', None, None, None, None)]"
      ]
     },
     "execution_count": 2086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getData(dbfile, 'SELECT * FROM authors WHERE id = 3;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f18ab",
   "metadata": {},
   "source": [
    "### `text_meta` table\n",
    "\n",
    "- id - primary key\n",
    "- author_id - foreign key `authors (id)`\n",
    "- author_name\n",
    "- title\n",
    "- editions - bibl. information\n",
    "- genre\n",
    "- pub_year - publication year\n",
    "- cr_year - creation year\n",
    "- fp_year - first published\n",
    "- tr_author_id - translator, foreign key `authors (id)`\n",
    "- tr_author_name\n",
    "- tr_lang - original language, translation only\n",
    "- orfl - original file name for debugging\n",
    "\n",
    "This table will be populated with `meta()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2058,
   "id": "77c69589",
   "metadata": {},
   "outputs": [],
   "source": [
    "lNames = {'deu':['de', 'Нямецкая' ], \\\n",
    "          'lat': ['la', 'Лацінская'], \\\n",
    "          'pol': ['pl', 'Польская'], \\\n",
    "          'rus': ['ru', 'Руская'], \\\n",
    "          'ukr': ['uk', 'Украінская'], \\\n",
    "          'yid': ['yi', 'Ідыш']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2059,
   "id": "1fb7c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "schTm = 'CREATE TABLE IF NOT EXISTS text_meta (id integer PRIMARY KEY, \\\n",
    "                                                author_id integer, \\\n",
    "                                                author_name text, \\\n",
    "                                                title text, \\\n",
    "                                                edition text, \\\n",
    "                                                genre text, \\\n",
    "                                                pub_year integer, \\\n",
    "                                                cr_year integer, \\\n",
    "                                                fp_year integer, \\\n",
    "                                                tr_author_id integer, \\\n",
    "                                                tr_author_name text, \\\n",
    "                                                tr_lang text, \\\n",
    "                                                orfl text, \\\n",
    "                                                FOREIGN KEY (author_id) REFERENCES authors (id), \\\n",
    "                                                FOREIGN KEY (tr_author_id) REFERENCES authors (id));'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2060,
   "id": "7228657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create meta table\n",
    "execute(dbfile, schTm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2061,
   "id": "f8acf480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id', 'INTEGER', 0, None, 1),\n",
       " (1, 'author_id', 'INTEGER', 0, None, 0),\n",
       " (2, 'author_name', 'TEXT', 0, None, 0),\n",
       " (3, 'title', 'TEXT', 0, None, 0),\n",
       " (4, 'edition', 'TEXT', 0, None, 0),\n",
       " (5, 'genre', 'TEXT', 0, None, 0),\n",
       " (6, 'pub_year', 'INTEGER', 0, None, 0),\n",
       " (7, 'cr_year', 'INTEGER', 0, None, 0),\n",
       " (8, 'fp_year', 'INTEGER', 0, None, 0),\n",
       " (9, 'tr_author_id', 'INTEGER', 0, None, 0),\n",
       " (10, 'tr_author_name', 'TEXT', 0, None, 0),\n",
       " (11, 'tr_lang', 'TEXT', 0, None, 0),\n",
       " (12, 'orfl', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 2061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getData(dbfile, 'PRAGMA table_info(text_meta)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444283f5",
   "metadata": {},
   "source": [
    "### `text_file` table\n",
    "\n",
    "- id - primary key, foreign key `text_meta (id)`\n",
    "- xml\n",
    "- txt \n",
    "- html\n",
    "\n",
    "This table contains all file assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2002,
   "id": "5e7cb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schTf = 'CREATE TABLE IF NOT EXISTS text_files (id integer NOT NULL PRIMARY KEY, \\\n",
    "                                                xml text, \\\n",
    "                                                txt text, \\\n",
    "                                                html text, \\\n",
    "                                                FOREIGN KEY (id) REFERENCES text_meta (id));'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2003,
   "id": "528ab677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file table\n",
    "execute(dbfile, schTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2004,
   "id": "2aa89e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id', 'INTEGER', 1, None, 1),\n",
       " (1, 'xml', 'TEXT', 0, None, 0),\n",
       " (2, 'txt', 'TEXT', 0, None, 0),\n",
       " (3, 'html', 'TEXT', 0, None, 0)]"
      ]
     },
     "execution_count": 2004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getData(dbfile, 'PRAGMA table_info(text_files)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59acccbb",
   "metadata": {},
   "source": [
    "### Virtual search index table\n",
    "\n",
    "The table will use SQLite3 FTS5 extention.\n",
    "\n",
    "- id - foreign key `text_meta (id)`\n",
    "- author\n",
    "- title\n",
    "- wordlist - string created by `searchInd()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2005,
   "id": "268dff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt = 'CREATE VIRTUAL TABLE search USING fts5(id, author, title, wordlist);'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2006,
   "id": "0929d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute(dbfile, vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2085,
   "id": "26f37810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id', '', 0, None, 0),\n",
       " (1, 'author', '', 0, None, 0),\n",
       " (2, 'title', '', 0, None, 0),\n",
       " (3, 'wordlist', '', 0, None, 0)]"
      ]
     },
     "execution_count": 2085,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getData(dbfile, 'PRAGMA table_info(search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadca13f",
   "metadata": {},
   "source": [
    "# Corpus database population\n",
    "\n",
    "The results of the previously defined functions are generated for every file and inserted into database.\n",
    "\n",
    "- `meta()` is the source of `text_meta` table values\n",
    "- `genTree() -> posTag()`, `simpleTxt()`, `mkHtml()` are written to `text_files` as well as to OS file system\n",
    "- `searchInd()` and some `meta()` values are stored in `search` virtual table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2052,
   "id": "9a65bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2055,
   "id": "12cb2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['../../assets', '../../assets/xml', '../../assets/txt', '../../assets/html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2338,
   "id": "7732c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in folders:\n",
    "    if not os.path.isdir(f):\n",
    "        os.mkdir(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2111,
   "id": "cc642d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test values\n",
    "execute(dbfile, 'INSERT INTO text_meta (id, orfl) values  (2, \"031_0012\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2112,
   "id": "0a65827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute(dbfile, 'delete from text_meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2278,
   "id": "55f10da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addedFiles(dbfile):\n",
    "    \"\"\"Get last ID and added files list\"\"\"\n",
    "    rows = getData(dbfile, 'select * from text_meta order by id desc')\n",
    "    \n",
    "    if rows:\n",
    "        lastId = rows[0][0]\n",
    "        files = [row[12] for row in rows]\n",
    "        \n",
    "    else:\n",
    "        lastId = 0\n",
    "        files = []\n",
    "    \n",
    "    return lastId, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2279,
   "id": "31bd3946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " ['003_0011',\n",
       "  '003_0010',\n",
       "  '003_0009',\n",
       "  '003_0008',\n",
       "  '003_0007',\n",
       "  '013_0008',\n",
       "  '013_0006',\n",
       "  '013_0005',\n",
       "  '013_0004',\n",
       "  '013_0003',\n",
       "  '013_0002',\n",
       "  '013_0001',\n",
       "  '007_0004',\n",
       "  '007_0002',\n",
       "  '007_0001',\n",
       "  '003_0011',\n",
       "  '003_0010',\n",
       "  '003_0009',\n",
       "  '003_0008',\n",
       "  '003_0007'])"
      ]
     },
     "execution_count": 2279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addedFiles(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2323,
   "id": "b3e71fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authors': 'Ян Баршчэўскі',\n",
       " 'CreationYear': '13.07.1841',\n",
       " 'Edition': 'Ян Баршчэўскі. Выбраныя творы. Менск, МФ «Беларускі кнігазбор», 1998.',\n",
       " 'FirstPublicationYear': '1842',\n",
       " 'LangOrig': 'pol',\n",
       " 'Pravapis': 'A1957',\n",
       " 'PublicationYear': '1998',\n",
       " 'SectionAuthor': 'Балады',\n",
       " 'StyleGenre': 'Балада',\n",
       " 'Title': 'Дзве бярозы',\n",
       " 'Title2': 'З народных паданняў',\n",
       " 'Translation': 'Кастусь Цьвірка',\n",
       " 'Forename': 'Ян',\n",
       " 'Surname': 'Баршчэўскі',\n",
       " 'aid': 7,\n",
       " 'trForename': 'Кастусь',\n",
       " 'trSurname': 'Цьвірка',\n",
       " 'tid': 77}"
      ]
     },
     "execution_count": 2323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta(getRaw(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2337,
   "id": "c8f7b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate(filelist, dbfile):\n",
    "    \n",
    "    added = addedFiles(dbfile)\n",
    "    \n",
    "    txid = added[0] + 1\n",
    "    done = added[1]\n",
    "    \n",
    "    cur = connect(dbfile).cursor()\n",
    "    \n",
    "    for file in filelist:\n",
    "\n",
    "        fname = None\n",
    "        fname = file.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        raw = None\n",
    "        metadict = None\n",
    "        tree = None\n",
    "        txt = None\n",
    "        xml = None\n",
    "        search = None\n",
    "        html = None\n",
    "\n",
    "        if fname not in done:\n",
    "\n",
    "            # generate files\n",
    "            \n",
    "            raw = getRaw(file)\n",
    "            metadict = meta(raw)\n",
    "            tree = genTree(raw, metadict, file)\n",
    "            txt = simpleTxt(tree)\n",
    "            xml = posTag(tree)\n",
    "            search = searchInd(xml)\n",
    "            html = mkHtml(xml)\n",
    "            \n",
    "            # text_meta\n",
    "            \n",
    "            metaTuple = (txid, \\\n",
    "                            metadict['aid'], \\\n",
    "                            metadict['Authors'], \\\n",
    "                            metadict['Title'], \\\n",
    "                            metadict['Edition'], \\\n",
    "                            metadict['StyleGenre'], \\\n",
    "                            metadict['PublicationYear'], \\\n",
    "                            metadict['CreationYear'], \\\n",
    "                            metadict['FirstPublicationYear'], \\\n",
    "                            metadict['tid'], \\\n",
    "                            metadict['Translation'], \\\n",
    "                            metadict['LangOrig'], \\\n",
    "                            fname)\n",
    "\n",
    "            cur.execute('INSERT INTO text_meta ( id, \\\n",
    "                                                author_id, \\\n",
    "                                                author_name, \\\n",
    "                                                title, \\\n",
    "                                                edition, \\\n",
    "                                                genre, \\\n",
    "                                                pub_year, \\\n",
    "                                                cr_year, \\\n",
    "                                                fp_year, \\\n",
    "                                                tr_author_id, \\\n",
    "                                                tr_author_name, \\\n",
    "                                                tr_lang, \\\n",
    "                                                orfl) values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', metaTuple)\n",
    "            \n",
    "            \n",
    "            # text_files\n",
    "            \n",
    "            fileTuple = (txid, str(xml), str(txt), str(html))\n",
    "            \n",
    "            cur.execute('INSERT INTO text_files ( id, \\\n",
    "                                                xml, \\\n",
    "                                                txt, \\\n",
    "                                                html ) values (?, ?, ?, ?)', fileTuple)\n",
    "            # search\n",
    "            \n",
    "            searchTuple = (txid, metadict['Authors'].lower(), metadict['Title'].lower(), search)\n",
    "            \n",
    "            cur.execute('INSERT INTO search ( id, \\\n",
    "                                                author, \\\n",
    "                                                title, \\\n",
    "                                                wordlist ) values (?, ?, ?, ?)', searchTuple)\n",
    "            \n",
    "            \n",
    "            # save files\n",
    "            \n",
    "            with open('../../assets/xml/' + str(txid) + '.xml', 'w') as xmlfile:\n",
    "                xmlfile.write(str(xml))\n",
    "                \n",
    "            with open('../../assets/txt/' + str(txid) + '.txt', 'w') as txtfile:\n",
    "                txtfile.write(str(txt))\n",
    "                \n",
    "            with open('../../assets/html/' + str(txid) + '.html', 'w') as htmlfile:\n",
    "                htmlfile.write(str(html))\n",
    "            \n",
    "            \n",
    "            txid += 1\n",
    "            done.append(fname)\n",
    "            \n",
    "\n",
    "    cur.close()\n",
    "    connect(dbfile).close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2387,
   "id": "851acb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate(pList[1][:3068], dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2355,
   "id": "01e87bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3068"
      ]
     },
     "execution_count": 2355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = pList[1][:3068]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2373,
   "id": "4ad443c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../../parsed/032_Алесь Гарун/032_0147.html'"
      ]
     },
     "execution_count": 2373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pList[1][1869]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2328,
   "id": "3bd82a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../parsed/032_Алесь Гарун/032_0016.html 1754\n",
      "../../../parsed/selected/032_0016.html 3123\n"
     ]
    }
   ],
   "source": [
    "for i,f in enumerate(pList[1]):\n",
    "    if '032_0015' in f:\n",
    "        print(pList[1][i + 1], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2358,
   "id": "d95d3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(pList[1]):\n",
    "    if '032_0015' in f:\n",
    "        print(pList[1][i + 1], i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357600f1",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c62953",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2382,
   "id": "16417197",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = 'SELECT id FROM search WHERE wordlist MATCH \"суомі\";'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2385,
   "id": "b1d61502",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[490, 747]"
      ]
     },
     "execution_count": 2385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [r[0] for r in getData(dbfile, req)]\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
